{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tuning SAM2 with Cityscapes dataset\n",
    "import os, sys\n",
    "import numpy as np\n",
    "KD_path = \"/home/avalocal/thesis23/KD\"\n",
    "sys.path.append(KD_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scratch:\\n  resolution: 1024\\n  train_batch_size: 1\\n  num_train_workers: 10\\n  num_frames: 8\\n  max_num_objects: 3\\n  base_lr: 5.0e-6\\n  vision_lr: 3.0e-06\\n  phases_per_epoch: 1\\n  num_epochs: 40'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scratch:\n",
    "  resolution: 1024\n",
    "  train_batch_size: 1\n",
    "  num_train_workers: 10\n",
    "  num_frames: 8\n",
    "  max_num_objects: 3\n",
    "  base_lr: 5.0e-6\n",
    "  vision_lr: 3.0e-06\n",
    "  phases_per_epoch: 1\n",
    "  num_epochs: 40'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "#dataset \n",
    "#images \n",
    "#annorations: labelIds\n",
    "#prompts: bboxes from labelIds (might consider or not)\n",
    "import os, sys, glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from cityscapes_original import CityscapesSV\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from loss_fns import MultiStepMultiMasksAndIous, sigmoid_focal_loss, dice_loss\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "#dataset and dataloaders\n",
    "# train_dataset = CityscapesSV(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\", split='train')\n",
    "train_dataset = CityscapesSV(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes/cityscapes_few_shot_instance\", split='train')\n",
    "\n",
    "print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "train_batch_size = 4\n",
    "num_train_workers = 4\n",
    "\n",
    "# image, instance, ids,  bbox, num_objects, file_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize_config_dir, compose\n",
    "from omegaconf import DictConfig\n",
    "import os\n",
    "#fine-tuning sam2\n",
    "ckpt_path = '/media/avalocal/T7/pardis/pardis/perception_system/ckpt/sam2.pth'\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import torch.nn as nn\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SAM2Model(nn.Module):   #used for teacher model of depth prediction\n",
    "    def __init__(self):\n",
    "        super(SAM2Model, self).__init__()\n",
    "\n",
    "        # sam2_checkpoint = os.path.join(current_dir, \"sam2/checkpoints/sam2.1_hiera_large.pt\")\n",
    "        sam2_checkpoint = \"/home/avalocal/thesis23/KD/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "        # model_cfg = \"sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "        model_cfg = \"sam2.1/sam2.1_hiera_l.yaml\"\n",
    "\n",
    "        config_dir = \"/home/avalocal/thesis23/KD/sam2/sam2/configs\"\n",
    "        with initialize_config_dir(version_base=None, config_dir=config_dir):\n",
    "            cfg = compose(config_name=model_cfg)\n",
    "            self.sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=DEVICE)\n",
    "            self.sam2_predictor = SAM2ImagePredictor(self.sam2_model)\n",
    "            self.sam2_predictor.model.sam_mask_decoder.train(True)\n",
    "            self.sam2_predictor.model.sam_prompt_encoder.train(True)\n",
    "        \n",
    "    def forward(self, x, bbox):\n",
    "        '''\n",
    "        input: x | should be np.array with size (h,w,3)\n",
    "        bbox: array w size (n, 4) where n is the number of bounding boxes\n",
    "        '''\n",
    "\n",
    "        # print(x.shape, bbox.shape)\n",
    "\n",
    "        # print(bbox, \"this is bbox\")\n",
    "        self.sam2_predictor.set_image(x)\n",
    "        # self.sam2_predictor.set_image_batch(x)\n",
    "        \n",
    "\n",
    "        # prompt encoding\n",
    "        mask_input, unnorm_coords, labels, unnorm_box = self.sam2_predictor._prep_prompts(\n",
    "            None, None, box=bbox, mask_logits=None, normalize_coords=True)\n",
    "\n",
    "        if unnorm_coords is not None:\n",
    "            concat_points = (unnorm_coords, labels)\n",
    "        else:\n",
    "            concat_points = None\n",
    "\n",
    "        if unnorm_box is not None:\n",
    "            box_coords = unnorm_box.reshape(-1, 2 , 2) #n,4 -> n,2,2\n",
    "            box_labels = torch.tensor([[2, 3]], dtype=torch.int, device=unnorm_box.device)\n",
    "            box_labels = box_labels.repeat(unnorm_box.size(0), 1)\n",
    "            # we merge \"boxes\" and \"points\" into a single \"concat_points\" input (where\n",
    "            # boxes are added at the beginning) to sam_prompt_encoder\n",
    "            if concat_points is not None:\n",
    "                concat_coords = torch.cat([box_coords, concat_points[0]], dim=1)\n",
    "                concat_labels = torch.cat([box_labels, concat_points[1]], dim=1)\n",
    "                concat_points = (concat_coords, concat_labels)\n",
    "            else:\n",
    "                concat_points = (box_coords, box_labels)\n",
    "\n",
    "        \n",
    "        sparse_embeddings, dense_embeddings = self.sam2_predictor.model.sam_prompt_encoder(\n",
    "            points=concat_points,\n",
    "            boxes = None,\n",
    "            masks = mask_input,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        # mask decoder\n",
    "\n",
    "        batched_mode = (\n",
    "            concat_points is not None and concat_points[0].shape[0] > 1\n",
    "        )  # multi object prediction\n",
    "        high_res_features = [\n",
    "            feat_level[-1].unsqueeze(0)\n",
    "            for feat_level in self.sam2_predictor._features[\"high_res_feats\"]\n",
    "        ]\n",
    "        low_res_masks, iou_predictions, _, _ = self.sam2_predictor.model.sam_mask_decoder(\n",
    "            image_embeddings=self.sam2_predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
    "            image_pe=self.sam2_predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
    "            sparse_prompt_embeddings=sparse_embeddings,\n",
    "            dense_prompt_embeddings=dense_embeddings,\n",
    "            multimask_output=False,\n",
    "            repeat_image=batched_mode,\n",
    "            high_res_features=high_res_features,\n",
    "        )\n",
    "\n",
    "        # Upscale the masks to the original image resolution\n",
    "        masks = self.sam2_predictor._transforms.postprocess_masks(\n",
    "            low_res_masks, self.sam2_predictor._orig_hw[-1]\n",
    "        )\n",
    "        \n",
    "        return masks\n",
    "\n",
    "\n",
    "# criterion = MultiStepMultiMasksAndIous(weight_dict={\"loss_mask\": 20.0, \"loss_dice\": 1.0, \"loss_iou\": 1.0})\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:15<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 18.447716997330446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:17<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 5.914421885846609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:17<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 4.2739150394876315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:18<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 3.859747359551579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:17<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 3.631058948585786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 3.4709260995129503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 3.348732205758612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Loss: 3.255269006074193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Loss: 3.178997950381543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Loss: 3.1143845606999223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 3.0639550642794875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:14<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 3.015183776257986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Loss: 2.9773099738431266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Loss: 2.9390687727066407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Loss: 2.906251747206033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Loss: 2.876699473484453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:12<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Loss: 2.849424304732357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:14<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Loss: 2.8269489429083214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:14<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train Loss: 2.804881959076387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:14<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train Loss: 2.782660714115005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:15<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 2.763823476182409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train Loss: 2.744198320141758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train Loss: 2.727749214114913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train Loss: 2.7113903502383865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train Loss: 2.697521881884839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train Loss: 2.6837164673460534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:14<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train Loss: 2.669616799756705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train Loss: 2.657783034336136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:12<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train Loss: 2.645510535642325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train Loss: 2.6353912612041794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train Loss: 2.624668228339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train Loss: 2.6152330794966363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train Loss: 2.605434307132859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train Loss: 2.597846235855516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train Loss: 2.588410651109305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train Loss: 2.581443270286882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train Loss: 2.5739943234317275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train Loss: 2.5667055084044677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train Loss: 2.561751758477774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train Loss: 2.555042524653745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train Loss: 2.550462647374854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train Loss: 2.5460859142154098\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train Loss: 2.541568780519876\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train Loss: 2.5376459367303963\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:11<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train Loss: 2.534249051507697\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train Loss: 2.5313204534082527\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train Loss: 2.5292087240391465\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:10<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train Loss: 2.5268445216029525\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:12<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train Loss: 2.525430271424443\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:12<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train Loss: 2.5244839076536247\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "#train loop\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, train_loader, optimizer, scheduler, DEVICE, epoch):\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        img, instance, ids, bbox, num_objects, file_name = batch\n",
    "        # print(img.shape, instance.shape, ids.shape, bbox.shape, num_objects, file_name)\n",
    "        #([4, 3, 1024, 2048]) ([4, 100, 1024, 2048]) ([4, 100]) ([4, 100, 4]) ([19, 50]) ('weimar_000091_000019_leftImg8bit.png',)\n",
    "        # img = img.to(DEVICE)\n",
    "        # instance = instance.to(DEVICE)\n",
    "        # bbox = bbox.to(DEVICE)\n",
    "        #resize image to 1024x1024\n",
    "\n",
    "\n",
    "        img *= 255.0 \n",
    "        img = F.interpolate(img, size=(1024, 1024), mode='bilinear', align_corners=False) #4, 3, 1024, 1024\n",
    "        img = img[0].permute(1, 2, 0).numpy().copy().astype(np.uint8)\n",
    "\n",
    "\n",
    "        # #if batch>1\n",
    "        # imgList = [img[i].permute(1, 2, 0).numpy().copy().astype(np.uint8) for i in range(img.shape[0])]\n",
    "        # bboxList =[bbox[i].numpy().copy().astype(np.float16) for i in range(bbox.shape[0])]\n",
    "        # print(imgList[0].shape, bboxList[0].shape, \"this should be input\")\n",
    "\n",
    "        # for bbox in bboxList:\n",
    "        #     bbox[:, [0, 2]] = bbox[:, [0, 2]] * 1024 / 2048\n",
    "        #     bbox[:, [1, 3]] = bbox[:, [1, 3]] * 1024 / 1024\n",
    "\n",
    "\n",
    "\n",
    "        bbox = bbox[0][:num_objects[0]].numpy()\n",
    "        bbox[:, [0, 2]] = bbox[:, [0, 2]] * 1024 / 2048\n",
    "        bbox[:, [1, 3]] = bbox[:, [1, 3]] * 1024 / 1024\n",
    "        # bbox = bbox.astype(np.float16)\n",
    "        # print(bbox.shape, \"this should be bbox\")\n",
    "\n",
    "        #resize instance from 1, 100, 1024, 2048 to 1, 100, 1024, 1024\n",
    "        instance = F.interpolate(instance, size=(1024, 1024), mode='nearest') #4, 100, 1024, 1024\n",
    "        instance = instance[0][:num_objects[0]]#.numpy().astype(np.float32)\n",
    "        instance = instance.to(DEVICE)\n",
    "\n",
    "        # print(img.shape, bbox.shape, instance.shape, \"this should be input\") #(1024, 1024, 3) (27, 4) torch.Size([27, 1024, 1024])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        # print(img.shape, bbox.shape, instance.shape, \"this should be input\") #(1024, 1024, 3) (27, 4) torch.Size([27, 1024, 1024])\n",
    "        # print(img.dtype, bbox.dtype, \"this should be input dtype\")           #uint8 float16 this should be input dtype\n",
    "\n",
    "        # masks, scores, logits = model(img, bbox)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # print(img.shape, bbox.shape, \"this should be input\")\n",
    "\n",
    "            if bbox.shape[0] == 0:\n",
    "                # masks = torch.zeros((0, 1024, 1024), dtype=torch.float32, device=DEVICE)\n",
    "                continue\n",
    "            else:\n",
    "\n",
    "                # masks= model(imgList, bboxList)\n",
    "                masks = model(img, bbox)\n",
    "            # print(masks.shape, masks.type(), masks.dtype, masks.requires_grad, \"this should be output\")\n",
    "            #torch.Size([12, 1, 1024, 1024]) torch.cuda.FloatTensor torch.float32 True this should be output\n",
    "\n",
    "            #masks numpy array to torch tensor\n",
    "            masks = masks.squeeze(1) #24, 1024, 1024\n",
    "        \n",
    "        #does masks require grad?\n",
    "        # print(masks.requires_grad, \"this should be True\")\n",
    "        # print(masks.shape, instance.shape, num_objects[0], \"this should be input\")\n",
    "        \n",
    "\n",
    "        #loss = 20 * focal loss + 1 * dice loss \n",
    "        # print(masks.shape, instance.shape, num_objects[0], \"this should be input\")\n",
    "        # if masks.shape != instance.shape:\n",
    "\n",
    "\n",
    "        focalLoss = sigmoid_focal_loss(masks, instance, num_objects[0], loss_on_multimask=False)\n",
    "        diceLoss = dice_loss(masks, instance, num_objects[0], loss_on_multimask=False)\n",
    "        # print(focalLoss, diceLoss, \"this should be loss\")\n",
    "        loss = 20 * focalLoss + 1 * diceLoss\n",
    "\n",
    "        # print(loss, \"this should be loss\")\n",
    "        # print(loss.requires_grad, \"this should be True\")\n",
    "        # print(\"type and dtype of loss\", loss.type(), loss.dtype)\n",
    "        \n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss/len(train_loader)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "model = SAM2Model()\n",
    "model = model.to(DEVICE)\n",
    "# model = nn.DataParallel(model)\n",
    "##image_encoder, memory_attention, memory_encoder, sam_prompt_encoder, sam_mask_decoder\n",
    "#freeze all layers except sam_prompt_encoder and sam_mask_decoder\n",
    "for name, param in model.named_parameters():\n",
    "    if 'sam_prompt_encoder' in name or 'sam_mask_decoder' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "optimizer = optim.AdamW(model.parameters(), lr=5.0e-6, weight_decay=1e-4, betas=(0.9, 0.999))\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = optim.lr_scheduler.PolynomialLR(optimizer, steps_per_epoch * num_epochs, power=1.0) #mask2former paper\n",
    "\n",
    "        \n",
    "\n",
    "#train loop\n",
    "min_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, scheduler, DEVICE, epoch)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss}')\n",
    "\n",
    "    if epoch > 40 and train_loss < min_loss:\n",
    "        min_loss = train_loss\n",
    "        #save model\n",
    "        torch.save(model.state_dict(), '/home/avalocal/thesis23/KD/sam2/checkpoints/sam2.1_hiera_large_finetuned_instance.pth')\n",
    "        print(\"model saved\")\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train loop with lr 1e-5\n",
    "# from tqdm import tqdm\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def train(model, train_loader, optimizer, scheduler, DEVICE, epoch):\n",
    "\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, batch in enumerate(tqdm(train_loader)):\n",
    "\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "#         img, instance, ids, bbox, num_objects, file_name = batch\n",
    "#         # print(img.shape, instance.shape, ids.shape, bbox.shape, num_objects, file_name)\n",
    "#         #([1, 3, 1024, 2048]) ([1, 100, 1024, 2048]) ([1, 100]) ([1, 100, 4]) ([19]) ('weimar_000091_000019_leftImg8bit.png',)\n",
    "\n",
    "#         #resize image to 1024x1024\n",
    "#         img *= 255.0\n",
    "#         img = F.interpolate(img, size=(1024, 1024), mode='bilinear', align_corners=False) #1, 3, 1024, 2048\n",
    "#         img = img[0].permute(1, 2, 0).numpy().copy().astype(np.uint8)\n",
    "\n",
    "#         bbox = bbox[0][:num_objects[0]].numpy()\n",
    "#         bbox[:, [0, 2]] = bbox[:, [0, 2]] * 1024 / 2048\n",
    "#         bbox[:, [1, 3]] = bbox[:, [1, 3]] * 1024 / 1024\n",
    "#         # bbox = bbox.astype(np.float16)\n",
    "#         # print(bbox.shape, \"this should be bbox\")\n",
    "\n",
    "#         #resize instance from 1, 100, 1024, 2048 to 1, 100, 1024, 1024\n",
    "#         instance = F.interpolate(instance, size=(1024, 1024), mode='nearest')\n",
    "#         instance = instance[0][:num_objects[0]]#.numpy().astype(np.float32)\n",
    "#         instance = instance.to(DEVICE)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "\n",
    "#         # print(img.shape, bbox.shape, instance.shape, \"this should be input\") #(1024, 1024, 3) (27, 4) torch.Size([27, 1024, 1024])\n",
    "#         # print(img.dtype, bbox.dtype, \"this should be input dtype\")           #uint8 float16 this should be input dtype\n",
    "\n",
    "#         # masks, scores, logits = model(img, bbox)\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             # print(img.shape, bbox.shape, \"this should be input\")\n",
    "\n",
    "#             if bbox.shape[0] == 0:\n",
    "#                 # masks = torch.zeros((0, 1024, 1024), dtype=torch.float32, device=DEVICE)\n",
    "#                 continue\n",
    "#             else:\n",
    "\n",
    "#                 masks= model(img, bbox) #(9, 1, 1024, 1024) (9, 1) (9, 1, 256, 256) this should be output\n",
    "\n",
    "#             # print(masks.shape, masks.type(), masks.dtype, masks.requires_grad, \"this should be output\")\n",
    "#             #torch.Size([12, 1, 1024, 1024]) torch.cuda.FloatTensor torch.float32 True this should be output\n",
    "\n",
    "#             #masks numpy array to torch tensor\n",
    "#             masks = masks.squeeze(1) #24, 1024, 1024\n",
    "        \n",
    "#         #does masks require grad?\n",
    "#         # print(masks.requires_grad, \"this should be True\")\n",
    "#         # print(masks.shape, instance.shape, num_objects[0], \"this should be input\")\n",
    "        \n",
    "\n",
    "#         #loss = 20 * focal loss + 1 * dice loss \n",
    "#         # print(masks.shape, instance.shape, num_objects[0], \"this should be input\")\n",
    "#         # if masks.shape != instance.shape:\n",
    "\n",
    "\n",
    "#         focalLoss = sigmoid_focal_loss(masks, instance, num_objects[0], loss_on_multimask=False)\n",
    "#         diceLoss = dice_loss(masks, instance, num_objects[0], loss_on_multimask=False)\n",
    "#         # print(focalLoss, diceLoss, \"this should be loss\")\n",
    "#         loss = 20 * focalLoss + 1 * diceLoss\n",
    "\n",
    "#         # print(loss, \"this should be loss\")\n",
    "#         # print(loss.requires_grad, \"this should be True\")\n",
    "#         # print(\"type and dtype of loss\", loss.type(), loss.dtype)\n",
    "        \n",
    "#         #backpropagation\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     return running_loss/len(train_loader)\n",
    "\n",
    "# num_epochs = 50\n",
    "\n",
    "# model = SAM2Model()\n",
    "# model = model.to(DEVICE)\n",
    "# ##image_encoder, memory_attention, memory_encoder, sam_prompt_encoder, sam_mask_decoder\n",
    "# #freeze all layers except sam_prompt_encoder and sam_mask_decoder\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'sam_prompt_encoder' in name or 'sam_mask_decoder' in name:\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "# optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.1, betas=(0.9, 0.999))\n",
    "# steps_per_epoch = len(train_loader)\n",
    "# scheduler = optim.lr_scheduler.PolynomialLR(optimizer, steps_per_epoch * num_epochs, power=1.0) #mask2former paper\n",
    "\n",
    "        \n",
    "\n",
    "# #train loop\n",
    "# min_loss = float('inf')\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     train_loss = train(model, train_loader, optimizer, scheduler, DEVICE, epoch)\n",
    "#     print(f'Epoch: {epoch}, Train Loss: {train_loss}')\n",
    "\n",
    "#     if epoch > 40 and train_loss < min_loss:\n",
    "#         min_loss = train_loss\n",
    "#         #save model\n",
    "#         # torch.save(model.state_dict(), '/home/avalocal/thesis23/KD/sam2/checkpoints/sam2.1_hiera_large_finetuned_instance_1e-5.pth')\n",
    "#         # print(\"model saved\")\n",
    "#         torch.save({\"model\": model.state_dict()}, '/home/avalocal/thesis23/KD/sam2/checkpoints/sam2.1_hiera_large_finetuned_instance_1e-5.pth')\n",
    "\n",
    "#         # sd = torch.load(ckpt_path, map_location=\"cpu\", weights_only=True)[\"model\"]\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:16<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 4.07701341015952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 3.6322245692104853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 3.4662152991575352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:02<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 3.3417233649522315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 3.216080929080979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 3.155846357295493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:10<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 3.120431284103073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Loss: 3.035674745665879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train Loss: 3.000940992441498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train Loss: 2.9390042023698824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:11<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 2.8954686994011665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 2.8812270799805138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:03<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train Loss: 2.8263395023646476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train Loss: 2.808108156689075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:02<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train Loss: 2.741322873450127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train Loss: 2.75375340121133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Loss: 2.70702330711509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:03<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train Loss: 2.6654157559961833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train Loss: 2.6605283053782807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train Loss: 2.614540869503462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train Loss: 2.581603661074358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train Loss: 2.569223797100933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train Loss: 2.5339034037379657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train Loss: 2.5212602134261815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train Loss: 2.4992155829046956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:10<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train Loss: 2.4672879649210375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train Loss: 2.4582269586184444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train Loss: 2.430763375263254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train Loss: 2.416460935112809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train Loss: 2.388058376577722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:11<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train Loss: 2.3612327498197554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train Loss: 2.3518617726824864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train Loss: 2.324620959042501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train Loss: 2.3056924906097542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train Loss: 2.2928087834951256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:09<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train Loss: 2.268720309423799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train Loss: 2.2552797561132607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:09<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train Loss: 2.2409872724478985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:04<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train Loss: 2.2217359466412487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train Loss: 2.200607710701077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:07<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train Loss: 2.186052501852773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train Loss: 2.1749580284627545\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train Loss: 2.1555940159579285\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:14<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train Loss: 2.1410434249168686\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:19<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train Loss: 2.126641331184812\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:02<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train Loss: 2.1147882975850787\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train Loss: 2.1028841783369288\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:08<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train Loss: 2.0926025253534317\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:06<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train Loss: 2.0834104298743883\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2975/2975 [12:04<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train Loss: 2.075776378958165\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# #train loop with lr 5e-5\n",
    "# from tqdm import tqdm\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def train(model, train_loader, optimizer, scheduler, DEVICE, epoch):\n",
    "\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, batch in enumerate(tqdm(train_loader)):\n",
    "\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "#         img, instance, ids, bbox, num_objects, file_name = batch\n",
    "#         # print(img.shape, instance.shape, ids.shape, bbox.shape, num_objects, file_name)\n",
    "#         #([1, 3, 1024, 2048]) ([1, 100, 1024, 2048]) ([1, 100]) ([1, 100, 4]) ([19]) ('weimar_000091_000019_leftImg8bit.png',)\n",
    "\n",
    "#         #resize image to 1024x1024\n",
    "#         img *= 255.0\n",
    "#         img = F.interpolate(img, size=(1024, 1024), mode='bilinear', align_corners=False) #1, 3, 1024, 2048\n",
    "#         img = img[0].permute(1, 2, 0).numpy().copy().astype(np.uint8)\n",
    "\n",
    "#         bbox = bbox[0][:num_objects[0]].numpy()\n",
    "#         bbox[:, [0, 2]] = bbox[:, [0, 2]] * 1024 / 2048\n",
    "#         bbox[:, [1, 3]] = bbox[:, [1, 3]] * 1024 / 1024\n",
    "#         # bbox = bbox.astype(np.float16)\n",
    "#         # print(bbox.shape, \"this should be bbox\")\n",
    "\n",
    "#         #resize instance from 1, 100, 1024, 2048 to 1, 100, 1024, 1024\n",
    "#         instance = F.interpolate(instance, size=(1024, 1024), mode='nearest')\n",
    "#         instance = instance[0][:num_objects[0]]#.numpy().astype(np.float32)\n",
    "#         instance = instance.to(DEVICE)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "\n",
    "#         # print(img.shape, bbox.shape, instance.shape, \"this should be input\") #(1024, 1024, 3) (27, 4) torch.Size([27, 1024, 1024])\n",
    "#         # print(img.dtype, bbox.dtype, \"this should be input dtype\")           #uint8 float16 this should be input dtype\n",
    "\n",
    "#         # masks, scores, logits = model(img, bbox)\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             # print(img.shape, bbox.shape, \"this should be input\")\n",
    "\n",
    "#             if bbox.shape[0] == 0:\n",
    "#                 # masks = torch.zeros((0, 1024, 1024), dtype=torch.float32, device=DEVICE)\n",
    "#                 continue\n",
    "#             else:\n",
    "\n",
    "#                 masks= model(img, bbox) #(9, 1, 1024, 1024) (9, 1) (9, 1, 256, 256) this should be output\n",
    "\n",
    "#             # print(masks.shape, masks.type(), masks.dtype, masks.requires_grad, \"this should be output\")\n",
    "#             #torch.Size([12, 1, 1024, 1024]) torch.cuda.FloatTensor torch.float32 True this should be output\n",
    "\n",
    "#             #masks numpy array to torch tensor\n",
    "#             masks = masks.squeeze(1) #24, 1024, 1024\n",
    "        \n",
    "#         #does masks require grad?\n",
    "#         # print(masks.requires_grad, \"this should be True\")\n",
    "#         # print(masks.shape, instance.shape, num_objects[0], \"this should be input\")\n",
    "        \n",
    "\n",
    "#         #loss = 20 * focal loss + 1 * dice loss \n",
    "#         # print(masks.shape, instance.shape, num_objects[0], \"this should be input\")\n",
    "#         # if masks.shape != instance.shape:\n",
    "\n",
    "\n",
    "#         focalLoss = sigmoid_focal_loss(masks, instance, num_objects[0], loss_on_multimask=False)\n",
    "#         diceLoss = dice_loss(masks, instance, num_objects[0], loss_on_multimask=False)\n",
    "#         # print(focalLoss, diceLoss, \"this should be loss\")\n",
    "#         loss = 20 * focalLoss + 1 * diceLoss\n",
    "\n",
    "#         # print(loss, \"this should be loss\")\n",
    "#         # print(loss.requires_grad, \"this should be True\")\n",
    "#         # print(\"type and dtype of loss\", loss.type(), loss.dtype)\n",
    "        \n",
    "#         #backpropagation\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     return running_loss/len(train_loader)\n",
    "\n",
    "# num_epochs = 50\n",
    "\n",
    "# model = SAM2Model()\n",
    "# model = model.to(DEVICE)\n",
    "# ##image_encoder, memory_attention, memory_encoder, sam_prompt_encoder, sam_mask_decoder\n",
    "# #freeze all layers except sam_prompt_encoder and sam_mask_decoder\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'sam_prompt_encoder' in name or 'sam_mask_decoder' in name:\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "# optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1, betas=(0.9, 0.999))\n",
    "# steps_per_epoch = len(train_loader)\n",
    "# scheduler = optim.lr_scheduler.PolynomialLR(optimizer, steps_per_epoch * num_epochs, power=1.0) #mask2former paper\n",
    "\n",
    "        \n",
    "\n",
    "# #train loop\n",
    "# min_loss = float('inf')\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     train_loss = train(model, train_loader, optimizer, scheduler, DEVICE, epoch)\n",
    "#     print(f'Epoch: {epoch}, Train Loss: {train_loss}')\n",
    "\n",
    "#     if epoch > 40 and train_loss < min_loss:\n",
    "#         min_loss = train_loss\n",
    "#         #save model\n",
    "#         torch.save({\"model\": model.state_dict()}, '/home/avalocal/thesis23/KD/sam2/checkpoints/sam2.1_hiera_large_finetuned_instance_5e-5.pth')\n",
    "#         print(\"model saved\")\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
