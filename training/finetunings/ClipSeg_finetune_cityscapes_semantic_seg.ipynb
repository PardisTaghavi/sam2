{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e245674c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######### DATASET #########\n",
    "#fine tuning SAM2 with Cityscapes dataset\n",
    "import os, sys\n",
    "import numpy as np\n",
    "KD_path = \"/home/avalocal/thesis23/KD\"\n",
    "sys.path.append(KD_path)\n",
    "#images \n",
    "#annorations: labelIds\n",
    "#prompts: bboxes from labelIds (might consider or not)\n",
    "import os, sys, glob, cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from labels import labels\n",
    "\n",
    "dic = {0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence', 5: 'pole', 6: 'traffic light', 7: 'traffic sign', 8: 'vegetation', 9: 'terrain', 10: 'sky'}\n",
    "num_to_color = {\n",
    "    0: [128, 64, 128],\n",
    "    1: [244, 35, 232],\n",
    "    2: [70, 70, 70],\n",
    "    3: [102, 102, 156],\n",
    "    4: [190, 153, 153],\n",
    "    5: [153, 153, 153],\n",
    "    6: [250, 170, 30],\n",
    "    7: [220, 220, 0],\n",
    "    8: [107, 142, 35],\n",
    "    9: [152, 251, 152],\n",
    "    10: [70, 130, 180]\n",
    "}\n",
    "\n",
    "id2trainId = { label.id: label.trainId for label in labels }\n",
    "trainId2color = { label.trainId: label.color for label in labels }\n",
    "\n",
    "#dataset getting images and labels\n",
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, root_dir, split='train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        if self.split in ['train', 'val', 'test']:\n",
    "            self.image_dir = os.path.join(self.root_dir, 'leftImg8bit', self.split)\n",
    "            self.label_dir = os.path.join(self.root_dir, 'gtFine', self.split)\n",
    "            self.image_files = glob.glob(os.path.join(self.image_dir, '*/*'))\n",
    "            self.label_files = glob.glob(os.path.join(self.label_dir, '*/*_labelIds.png'))\n",
    "            self.color_files = glob.glob(os.path.join(self.label_dir, '*/*_color.png'))\n",
    "            self.image_files.sort()\n",
    "            self.label_files.sort()\n",
    "            self.color_files.sort()\n",
    "        elif self.split in ['train_extra']:\n",
    "            self.image_dir = os.path.join(self.root_dir, 'leftImg8bit', 'train_extra')\n",
    "            self.image_files = glob.glob(os.path.join(self.image_dir, '*/*'))\n",
    "            #shuffle the images\n",
    "            np.random.shuffle(self.image_files)\n",
    "            #pick only 3000 images\n",
    "            self.image_files = self.image_files[:3000]\n",
    "\n",
    "        self.stuff_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        self.instace_classes = [11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        \n",
    "        assert os.path.exists(self.image_files[idx]), self.image_files[idx]\n",
    "\n",
    "        file_name = os.path.basename(self.image_files[idx])\n",
    "\n",
    "\n",
    "        # print(len(self.image_files), len(self.label_files))\n",
    "        image = cv2.imread(self.image_files[idx], cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #H, W, C\n",
    "        cropped_image = image[0:970, 0:2048]\n",
    "        image = cv2.resize(cropped_image, (2048, 1024), interpolation=cv2.INTER_LINEAR)\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float() #3, H, W\n",
    "        image = image / 255.0\n",
    "        # print(self.label_files[idx])\n",
    "\n",
    "        if self.split in ['train', 'val', 'test']:\n",
    "            label_rgb = cv2.imread(self.color_files[idx], cv2.IMREAD_COLOR)\n",
    "            label_rgb = cv2.cvtColor(label_rgb, cv2.COLOR_BGR2RGB) #H, W, C\n",
    "            label_rgb = torch.from_numpy(label_rgb)\n",
    "            label = cv2.imread(self.label_files[idx], cv2.IMREAD_GRAYSCALE) #H, W\n",
    "            label = np.vectorize(id2trainId.get)(label)\n",
    "            label = torch.from_numpy(label).unsqueeze(0).float() #1, H, W\n",
    "       \n",
    "            #stuff label\n",
    "            label_rgb_stuff = torch.zeros(label.size(1), label.size(2), 3).to(torch.long)\n",
    "            for i in range(11):\n",
    "                # label_rgb_stuff = label_rgb_stuff.to(torch.long)  # Ensure destination tensor is Long\n",
    "                label_rgb_stuff[(label == i).squeeze()] = torch.tensor(num_to_color[i], dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "            N = 11 # 11 stuff classes + 1 void class\n",
    "            stuff_label= torch.zeros(N, label.size(1), label.size(2))\n",
    "            for i in range(N):\n",
    "                stuff_label[i] = (label == i).float()\n",
    "        \n",
    "            return image, label_rgb_stuff, stuff_label  # 3, H, W | 12, H, W\n",
    "        elif self.split in ['train_extra']:\n",
    "            return image, file_name\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\", split='train')\n",
    "train_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",\n",
    "            split='val')\n",
    "# print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "\n",
    "train_batch_size = 4\n",
    "num_train_workers = 4\n",
    "print(len(train_dataset))\n",
    "\n",
    "img, label_rgb, stuff_label = next(iter(train_loader))\n",
    "#show rgb label\n",
    "plt.imshow(label_rgb[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (5.2.0)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#########FINE TUNING CLIPSEG#########\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoProcessor, CLIPSegForImageSegmentation\n",
    "from tqdm import tqdm\n",
    "\n",
    "finetuning = False \n",
    "if finetuning:\n",
    "    processor = AutoProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "    model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    epochs = 100\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2, betas=(0.9, 0.999))\n",
    "    # optimizer = ADOPT(model.parameters(), lr=5e-5,decouple=True)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=1e-8)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    texts = [\"road\", \"sidewalk\", \"building\", \"wall\", \"fence\", \"pole\", \"traffic light\", \"traffic sign\", \"vegetation\", \"terrain\", \"sky\"]\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for _, batch in enumerate(tqdm(dataloader)):\n",
    "            images, masks = batch\n",
    "            images = images[0].to(device)\n",
    "            \n",
    "            inputs = processor(text=texts,images=[images] * len(texts), padding=True, return_tensors=\"pt\")\n",
    "            # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "            masks = masks[0].to(device) #11, H, W\n",
    "            for k in inputs.keys():\n",
    "                inputs[k] = inputs[k].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # print(logits.shape, masks.shape) # 11, 352, 352 | 11, 1024, 2048\n",
    "\n",
    "            # approach 1) upscale logits to the size of masks\n",
    "            logits = logits.unsqueeze(0)\n",
    "            logits = torch.nn.functional.interpolate(logits, size=(masks.size(1), masks.size(2)), mode=\"bilinear\", align_corners=False)\n",
    "            logits = logits.squeeze(0)\n",
    "\n",
    "            # 2) approach Downsample masks to the size of logits\n",
    "            # masks = torch.nn.functional.interpolate(masks.unsqueeze(0), size=(logits.size(1), logits.size(2)), mode=\"bilinear\", align_corners=False)\n",
    "            # masks = masks.squeeze(0)\n",
    "\n",
    "\n",
    "            # print(logits.shape, masks.shape)\n",
    "            # print(logits.requires_grad, masks.requires_grad,\"logits, masks require grad\") #True, False\n",
    "\n",
    "            # Compute loss for each class (assuming masks are binary)\n",
    "            loss = criterion(logits, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(dataloader)}\")\n",
    "\n",
    "    #save the model\n",
    "    torch.save(model.state_dict(), \"/home/avalocal/thesis23/KD/sam2/checkpoints/clipseg_finetuned_semantic_cityscapes_1e-5_100epochs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########EVALUATION#########\n",
    "import os, json, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys, os\n",
    "import torch, random\n",
    "import torch.nn as nn\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "GlobalHydra.instance().clear()\n",
    "from hydra import initialize\n",
    "from transformers import AutoProcessor, CLIPSegForImageSegmentation\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_miou(pred, gt):\n",
    "\n",
    "    num_classes = torch.unique(gt).size(0)\n",
    "    #pred H, W, C\n",
    "    #gt H, W, C\n",
    "    \n",
    "    ious = []\n",
    "    for i in range(num_classes):\n",
    "        pred_i = pred == i\n",
    "        gt_i = gt == i\n",
    "        intersection = (pred_i & gt_i).sum()\n",
    "        union = (pred_i | gt_i).sum()\n",
    "        iou = intersection / union\n",
    "        ious.append(iou.item())\n",
    "    #mean iou of not nan values\n",
    "    miou = np.nanmean(ious)\n",
    "    \n",
    "    return miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stuff classes 11-class\n",
    "dic = {0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence', 5: 'pole', 6: 'traffic light', 7: 'traffic sign', 8: 'vegetation', 9: 'terrain', 10: 'sky'}\n",
    "num_to_color = {0: [128, 64, 128], 1: [244, 35, 232], 2: [70, 70, 70], 3: [102, 102, 156],\n",
    "                4: [190, 153, 153], 5: [153, 153, 153],6: [250, 170, 30], 7: [220, 220, 0],\n",
    "                8: [107, 142, 35], 9: [152, 251, 152], 10: [70, 130, 180]}\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    mask = mask.detach().cpu().numpy()\n",
    "    color_mask = np.zeros((mask.shape[1], mask.shape[2], 3))\n",
    "    for i in range(mask.shape[0]):\n",
    "        color = num_to_color[i]\n",
    "        color_mask[mask[i] == 1] = color\n",
    "    return color_mask\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sam2_checkpoint = \"/home/avalocal/thesis23/KD/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"sam2.1_hiera_l.yaml\"\n",
    "#/home/avalocal/thesis23/KD/sam2/sam2/configs/sam2.1\n",
    "\n",
    "# Replace this path with the actual path to your config directory\n",
    "# config_dir = \"sam2/sam2/configs/sam2.1\"\n",
    "config_dir = \"sam2/sam2/configs/sam2.1\"\n",
    "with initialize(version_base=None, config_path=config_dir):\n",
    "    sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  0%|          | 1/500 [00:03<26:35,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
      "MIoU for frame 0: 0.371706485748291\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:05<23:18,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 1: 0.4938819408416748\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [00:08<21:49,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 2: 0.5382415652275085\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/500 [00:11<22:45,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 3: 0.5682397484779358\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [00:13<21:53,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 4: 0.3118884563446045\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/500 [00:16<21:35,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 5: 0.32947608828544617\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 7/500 [00:18<21:48,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 6: 0.4088532626628876\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 8/500 [00:21<22:17,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 7: 0.49974051117897034\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 9/500 [00:24<22:18,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 8: 0.5567197799682617\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 10/500 [00:26<21:36,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 9: 0.29944083094596863\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 11/500 [00:29<21:34,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 10: 0.27951517701148987\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 12/500 [00:32<21:37,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 11: 0.3746744990348816\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 13/500 [00:34<21:03,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 12: 0.3119053244590759\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 14/500 [00:37<21:13,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 13: 0.345084547996521\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 15/500 [00:39<21:01,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 14: 0.26399680972099304\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 16/500 [00:42<20:34,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 15: 0.22237271070480347\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 17/500 [00:45<20:45,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 16: 0.2610146403312683\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 18/500 [00:47<21:08,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 17: 0.24998924136161804\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 19/500 [00:50<20:41,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 18: 0.30896157026290894\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 20/500 [00:52<20:41,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 19: 0.3037339746952057\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 21/500 [00:55<20:41,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 20: 0.38494595885276794\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 22/500 [00:58<20:34,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 21: 0.5440046787261963\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 23/500 [01:01<22:07,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 22: 0.22177498042583466\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 24/500 [01:04<22:03,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 23: 0.22267495095729828\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 25/500 [01:06<21:04,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 24: 0.31693515181541443\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 26/500 [01:09<20:57,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 25: 0.4202013313770294\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 27/500 [01:11<20:47,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 26: 0.4319404065608978\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 28/500 [01:14<20:27,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 27: 0.2514256238937378\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 29/500 [01:19<27:12,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 28: 0.43881678581237793\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 30/500 [01:22<26:10,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 29: 0.5921748876571655\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 31/500 [01:25<24:39,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 30: 0.35035741329193115\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 32/500 [01:28<24:03,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 31: 0.3288322389125824\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 33/500 [01:31<23:14,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 32: 0.5121079683303833\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 34/500 [01:33<22:25,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 33: 0.23176738619804382\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 35/500 [01:37<24:58,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 34: 0.4697398543357849\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 36/500 [01:41<26:19,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 35: 0.21360184252262115\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 37/500 [01:45<27:05,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 36: 0.36460307240486145\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 38/500 [01:49<27:55,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 37: 0.2500828504562378\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 39/500 [01:53<29:08,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 38: 0.3806622326374054\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 40/500 [01:57<29:16,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 39: 0.2542046010494232\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 41/500 [02:01<29:18,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 40: 0.4103870987892151\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 42/500 [02:05<29:25,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 41: 0.40735357999801636\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 43/500 [02:09<29:40,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 42: 0.3978363573551178\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 44/500 [02:13<30:29,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 43: 0.5642354488372803\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 45/500 [02:18<32:38,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 44: 0.370463490486145\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 46/500 [02:22<31:57,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 45: 0.36013662815093994\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 47/500 [02:25<30:28,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 46: 0.32182592153549194\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 48/500 [02:29<30:12,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 47: 0.34036746621131897\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 49/500 [02:33<29:44,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 48: 0.4318869411945343\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 50/500 [02:37<29:22,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 49: 0.31991031765937805\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 51/500 [02:41<30:02,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 50: 0.2431207001209259\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 52/500 [02:45<30:08,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 51: 0.18434740602970123\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 53/500 [02:48<27:50,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 52: 0.2315710335969925\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 54/500 [02:51<26:15,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 53: 0.36376848816871643\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 55/500 [02:54<23:45,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 54: 0.25834882259368896\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 56/500 [02:57<22:20,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 55: 0.3067892789840698\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|        | 57/500 [03:00<22:14,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 56: 0.2635326385498047\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 58/500 [03:02<21:12,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 57: 0.40363386273384094\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 59/500 [03:05<20:21,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 58: 0.30129632353782654\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 60/500 [03:07<19:56,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 59: 0.3839099705219269\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 61/500 [03:10<19:23,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 60: 0.28483206033706665\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 62/500 [03:12<18:49,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 61: 0.3364107012748718\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 63/500 [03:15<19:07,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 62: 0.2814038395881653\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 64/500 [03:17<18:39,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 63: 0.3455717861652374\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 65/500 [03:21<20:53,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 64: 0.4599123001098633\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 66/500 [03:24<20:34,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 65: 0.3108270764350891\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 67/500 [03:26<20:21,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 66: 0.29703250527381897\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 68/500 [03:29<19:49,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 67: 0.37461718916893005\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 69/500 [03:32<19:52,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 68: 0.31783947348594666\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 70/500 [03:34<19:20,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 69: 0.23947256803512573\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 71/500 [03:38<20:51,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 70: 0.34530043601989746\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 72/500 [03:41<20:41,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 71: 0.3981473445892334\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 73/500 [03:43<20:17,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 72: 0.27999335527420044\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 74/500 [03:46<20:13,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 73: 0.30975523591041565\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 75/500 [03:49<19:33,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 74: 0.3700321912765503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 76/500 [03:51<18:36,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
      "MIoU for frame 75: 0.3389863669872284\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 77/500 [03:56<24:00,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 76: 0.5312625765800476\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 78/500 [03:59<22:33,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 77: 0.41469624638557434\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 79/500 [04:02<21:16,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 78: 0.4014563262462616\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 80/500 [04:04<20:27,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 79: 0.4134626090526581\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 81/500 [04:07<19:53,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 80: 0.5142656564712524\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 82/500 [04:10<19:10,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 81: 0.3654193878173828\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 83/500 [04:12<18:47,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 82: 0.3363356590270996\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 84/500 [04:15<18:49,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 83: 0.373188316822052\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 85/500 [04:17<18:31,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 84: 0.39457961916923523\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 86/500 [04:20<18:44,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 85: 0.39944496750831604\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 87/500 [04:23<19:25,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 86: 0.605453372001648\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 88/500 [04:26<18:44,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 87: 0.38124069571495056\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 89/500 [04:28<18:23,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 88: 0.30352982878685\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 90/500 [04:31<17:33,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 89: 0.4975723326206207\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 91/500 [04:33<17:19,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 90: 0.2801985442638397\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 92/500 [04:36<17:27,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 91: 0.3312917649745941\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 93/500 [04:39<17:50,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 92: 0.23128996789455414\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 94/500 [04:41<17:33,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 93: 0.4400743842124939\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 95/500 [04:44<17:29,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 94: 0.5808297395706177\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 96/500 [04:47<18:43,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 95: 0.4912961721420288\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 97/500 [04:49<18:05,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 96: 0.22181876003742218\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 98/500 [04:52<18:27,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 97: 0.452693909406662\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 99/500 [04:55<18:34,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 98: 0.4802192449569702\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 100/500 [04:58<17:38,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 99: 0.2975977063179016\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 101/500 [05:00<17:39,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 100: 0.4434428811073303\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 102/500 [05:03<17:36,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 101: 0.3144461512565613\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 103/500 [05:05<17:27,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 102: 0.30087345838546753\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 104/500 [05:08<17:05,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 103: 0.20696289837360382\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 105/500 [05:11<17:13,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 104: 0.2985921800136566\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 106/500 [05:13<16:53,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 105: 0.29821082949638367\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|       | 107/500 [05:16<16:41,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 106: 0.19036036729812622\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 108/500 [05:18<16:47,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 107: 0.283308207988739\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 109/500 [05:21<16:38,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 108: 0.330230176448822\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 110/500 [05:23<16:42,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 109: 0.2599518299102783\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 111/500 [05:26<16:51,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 110: 0.34725987911224365\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 112/500 [05:28<16:37,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 111: 0.3575308620929718\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 113/500 [05:31<16:07,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 112: 0.24237798154354095\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 114/500 [05:34<17:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 113: 0.436369925737381\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 115/500 [05:36<16:44,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 114: 0.38760441541671753\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 116/500 [05:40<19:01,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 115: 0.3247881531715393\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 117/500 [05:43<19:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 116: 0.3914847671985626\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 118/500 [05:48<22:40,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 117: 0.4972991943359375\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 119/500 [05:55<28:59,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 118: 0.5381292700767517\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 120/500 [05:59<27:42,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 119: 0.3193979561328888\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 121/500 [06:03<26:25,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 120: 0.4982093870639801\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 122/500 [06:07<25:56,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 121: 0.3865983784198761\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 123/500 [06:11<26:04,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 122: 0.24959178268909454\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 124/500 [06:14<23:58,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 123: 0.26877033710479736\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 125/500 [06:18<24:53,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 124: 0.552821159362793\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 126/500 [06:22<23:34,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 125: 0.6331633925437927\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 127/500 [06:25<23:24,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 126: 0.35543981194496155\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 128/500 [06:28<22:12,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 127: 0.48747488856315613\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 129/500 [06:32<22:11,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 128: 0.48548048734664917\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 130/500 [06:36<22:11,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 129: 0.5279405117034912\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 131/500 [06:40<23:11,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 130: 0.6376553177833557\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 132/500 [06:43<22:06,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 131: 0.5702821016311646\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 133/500 [06:47<22:11,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 132: 0.253217488527298\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 134/500 [06:50<20:48,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 133: 0.6118246912956238\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 135/500 [06:52<18:59,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 134: 0.5123493671417236\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 136/500 [06:55<17:57,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 135: 0.5536252856254578\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 137/500 [06:57<17:20,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 136: 0.16849805414676666\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 138/500 [07:00<16:15,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 137: 0.3485332429409027\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 139/500 [07:02<16:32,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 138: 0.4786660373210907\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 140/500 [07:06<17:12,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 139: 0.5428112745285034\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 141/500 [07:08<16:32,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 140: 0.4820557236671448\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 142/500 [07:11<16:01,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 141: 0.393702894449234\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 143/500 [07:13<15:57,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 142: 0.34356260299682617\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 144/500 [07:16<15:17,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 143: 0.36127400398254395\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 145/500 [07:18<15:07,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 144: 0.4629172682762146\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 146/500 [07:21<15:25,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 145: 0.5072575807571411\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 147/500 [07:24<15:19,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 146: 0.1890755295753479\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 148/500 [07:26<15:30,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 147: 0.2591516375541687\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 149/500 [07:29<15:22,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 148: 0.24558278918266296\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 150/500 [07:31<15:16,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 149: 0.35356417298316956\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 151/500 [07:34<15:35,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 150: 0.3795904517173767\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 152/500 [07:37<15:26,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 151: 0.2561996579170227\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 153/500 [07:39<15:01,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 152: 0.28843429684638977\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 154/500 [07:42<15:04,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 153: 0.2807687520980835\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 155/500 [07:45<15:38,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 154: 0.5355983376502991\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 156/500 [07:47<15:10,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 155: 0.4119817912578583\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|      | 157/500 [07:50<15:24,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 156: 0.32546672224998474\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 158/500 [07:53<15:16,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 157: 0.2851817011833191\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 159/500 [07:55<14:45,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 158: 0.2794986963272095\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 160/500 [07:58<14:55,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 159: 0.21067692339420319\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 161/500 [08:01<14:50,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 160: 0.3819660544395447\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 162/500 [08:03<14:19,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 161: 0.34288936853408813\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 163/500 [08:06<14:18,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 162: 0.18328353762626648\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 164/500 [08:08<14:25,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 163: 0.2951544523239136\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 165/500 [08:10<13:58,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 164: 0.48213401436805725\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 166/500 [08:13<14:16,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 165: 0.6363152265548706\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 167/500 [08:16<15:11,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 166: 0.6309529542922974\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 168/500 [08:19<14:47,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 167: 0.5292761921882629\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 169/500 [08:21<14:13,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 168: 0.3481677174568176\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 170/500 [08:24<14:39,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 169: 0.6263371109962463\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 171/500 [08:27<14:14,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 170: 0.23759707808494568\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 172/500 [08:29<13:56,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 171: 0.2938525080680847\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 173/500 [08:32<14:01,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 172: 0.3046870827674866\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 174/500 [08:34<14:12,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 173: 0.47445380687713623\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 175/500 [08:37<14:35,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 174: 0.4586615562438965\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 176/500 [08:40<15:16,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 175: 0.4313083291053772\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 177/500 [08:43<15:07,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 176: 0.2274819314479828\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 178/500 [08:46<14:55,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 177: 0.3506351411342621\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 179/500 [08:48<14:34,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 178: 0.25331544876098633\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 180/500 [08:51<14:17,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 179: 0.387994647026062\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 181/500 [08:54<14:04,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 180: 0.2128133773803711\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 182/500 [08:56<14:01,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 181: 0.4544302523136139\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 183/500 [08:59<13:50,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 182: 0.5053663849830627\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 184/500 [09:01<13:33,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 183: 0.45649781823158264\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 185/500 [09:04<13:16,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 184: 0.3624747693538666\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 186/500 [09:06<13:02,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 185: 0.5177198648452759\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 187/500 [09:09<13:08,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 186: 0.535785436630249\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 188/500 [09:12<13:51,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 187: 0.39136022329330444\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 189/500 [09:14<13:50,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 188: 0.505893349647522\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 190/500 [09:17<13:29,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 189: 0.6051239371299744\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 191/500 [09:20<14:03,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 190: 0.5354390740394592\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 192/500 [09:22<13:46,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 191: 0.4164510667324066\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 193/500 [09:25<13:38,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 192: 0.46079784631729126\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 194/500 [09:28<13:48,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 193: 0.32238680124282837\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 195/500 [09:30<13:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 194: 0.3709920346736908\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 196/500 [09:33<13:40,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 195: 0.4280901849269867\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 197/500 [09:37<14:54,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 196: 0.3542613089084625\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 198/500 [09:40<16:06,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 197: 0.33891555666923523\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 199/500 [09:44<16:29,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 198: 0.325962096452713\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 200/500 [09:48<18:15,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 199: 0.38759779930114746\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 201/500 [09:52<17:50,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 200: 0.6363545060157776\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 202/500 [09:56<18:25,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 201: 0.4938659965991974\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 203/500 [10:00<18:59,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 202: 0.4630679488182068\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 204/500 [10:04<19:12,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 203: 0.528751790523529\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 205/500 [10:08<19:32,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 204: 0.44610413908958435\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 206/500 [10:12<18:56,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 205: 0.43650683760643005\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 207/500 [10:15<18:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 206: 0.4331119954586029\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 208/500 [10:19<17:44,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 207: 0.18014588952064514\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 209/500 [10:23<18:35,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 208: 0.44723379611968994\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 210/500 [10:27<18:41,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 209: 0.38297346234321594\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 211/500 [10:31<18:20,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 210: 0.600286066532135\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 212/500 [10:35<18:35,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 211: 0.5139694213867188\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 213/500 [10:38<18:26,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 212: 0.5947374105453491\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 214/500 [10:42<17:30,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 213: 0.2797677516937256\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 215/500 [10:45<17:24,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 214: 0.13024935126304626\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 216/500 [10:48<15:33,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 215: 0.2541710138320923\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 217/500 [10:50<14:45,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 216: 0.2203313261270523\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 218/500 [10:53<14:10,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 217: 0.31278106570243835\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 219/500 [10:56<13:23,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 218: 0.24775119125843048\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 220/500 [10:58<13:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 219: 0.2650648355484009\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 221/500 [11:01<13:20,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 220: 0.44895094633102417\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 222/500 [11:04<12:54,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 221: 0.4908501207828522\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 223/500 [11:07<12:35,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 222: 0.5469098687171936\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 224/500 [11:09<12:37,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 223: 0.5093650817871094\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 225/500 [11:12<12:06,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 224: 0.5156496167182922\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 226/500 [11:15<12:18,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 225: 0.5292078852653503\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 227/500 [11:17<12:12,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 226: 0.4005553424358368\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 228/500 [11:20<11:52,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 227: 0.33755579590797424\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 229/500 [11:23<12:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 228: 0.37261754274368286\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 230/500 [11:25<11:55,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 229: 0.3351094722747803\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 231/500 [11:28<12:05,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 230: 0.2700730264186859\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 232/500 [11:31<12:43,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 231: 0.5228570699691772\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 233/500 [11:34<12:44,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 232: 0.5230585336685181\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 234/500 [11:37<12:22,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 233: 0.49697282910346985\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 235/500 [11:39<12:17,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 234: 0.38043931126594543\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 236/500 [11:42<12:07,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 235: 0.4236024022102356\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 237/500 [11:45<12:07,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 236: 0.6023885011672974\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 238/500 [11:48<11:59,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 237: 0.425311416387558\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 239/500 [11:50<11:46,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 238: 0.1931696981191635\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 240/500 [11:53<11:23,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 239: 0.23166261613368988\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 241/500 [11:55<11:27,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 240: 0.5166988372802734\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 242/500 [11:58<11:34,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 241: 0.4212932586669922\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 243/500 [12:01<11:42,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 242: 0.427445650100708\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 244/500 [12:04<11:37,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 243: 0.5135595202445984\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 245/500 [12:06<11:35,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 244: 0.2640245258808136\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 246/500 [12:09<11:16,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 245: 0.19419078528881073\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 247/500 [12:12<11:40,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 246: 0.3024758994579315\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 248/500 [12:15<12:01,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 247: 0.30325788259506226\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 249/500 [12:17<11:26,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 248: 0.46462053060531616\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 250/500 [12:20<11:38,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 249: 0.539205014705658\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 251/500 [12:23<11:24,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 250: 0.3623795807361603\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 252/500 [12:26<11:02,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 251: 0.36789146065711975\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 253/500 [12:28<11:09,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 252: 0.5311571955680847\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 254/500 [12:31<11:09,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 253: 0.29034239053726196\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 255/500 [12:34<10:48,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 254: 0.3986944258213043\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 256/500 [12:37<11:09,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 255: 0.47385886311531067\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 257/500 [12:39<10:54,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 256: 0.46906596422195435\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 258/500 [12:41<10:22,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 257: 0.19226913154125214\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 259/500 [12:44<10:25,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 258: 0.27320319414138794\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 260/500 [12:47<10:51,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 259: 0.5830212235450745\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 261/500 [12:49<10:20,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 260: 0.3259887099266052\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 262/500 [12:52<10:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 261: 0.3063206672668457\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 263/500 [12:55<10:45,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 262: 0.2291031926870346\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 264/500 [12:58<10:26,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 263: 0.4598005712032318\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 265/500 [13:00<10:27,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 264: 0.1592029184103012\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 266/500 [13:03<10:23,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 265: 0.31741389632225037\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 267/500 [13:05<10:13,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 266: 0.483076274394989\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 268/500 [13:08<10:17,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 267: 0.37101998925209045\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 269/500 [13:11<10:29,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 268: 0.6420558094978333\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 270/500 [13:13<10:07,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 269: 0.2787257730960846\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 271/500 [13:16<10:10,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 270: 0.310833603143692\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 272/500 [13:19<10:17,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 271: 0.24268211424350739\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 273/500 [13:22<10:11,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 272: 0.2453910857439041\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 274/500 [13:24<09:55,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 273: 0.1862628310918808\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 275/500 [13:27<09:35,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 274: 0.22829362750053406\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 276/500 [13:29<09:24,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 275: 0.2740032970905304\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 277/500 [13:32<09:35,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 276: 0.2273050844669342\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 278/500 [13:35<10:39,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 277: 0.20331193506717682\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 279/500 [13:39<11:52,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 278: 0.09195305407047272\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 280/500 [13:42<11:42,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 279: 0.2263457030057907\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 281/500 [13:46<12:13,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 280: 0.22413161396980286\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 282/500 [13:50<12:41,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 281: 0.2972734570503235\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 283/500 [13:53<12:37,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 282: 0.28553974628448486\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 284/500 [13:57<12:39,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 283: 0.2210605889558792\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 285/500 [14:01<13:06,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 284: 0.10001344978809357\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 286/500 [14:05<13:39,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 285: 0.2281186431646347\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 287/500 [14:09<13:28,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 286: 0.1315816193819046\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 288/500 [14:13<13:31,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 287: 0.13043053448200226\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 289/500 [14:17<13:41,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 288: 0.1395900696516037\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 290/500 [14:22<14:21,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 289: 0.14468473196029663\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 291/500 [14:25<13:43,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 290: 0.2944231629371643\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 292/500 [14:29<13:48,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 291: 0.3540075123310089\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 293/500 [14:33<13:37,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 292: 0.3405989110469818\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 294/500 [14:37<13:08,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 293: 0.5178135633468628\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 295/500 [14:40<12:47,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 294: 0.5693602561950684\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 296/500 [14:43<11:33,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 295: 0.42215827107429504\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 297/500 [14:45<10:51,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 296: 0.29395395517349243\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 298/500 [14:48<10:28,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 297: 0.13997477293014526\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 299/500 [14:51<10:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 298: 0.3263989984989166\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 300/500 [14:54<09:38,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 299: 0.1647317111492157\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 301/500 [14:56<09:16,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 300: 0.47959285974502563\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 302/500 [15:00<09:37,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 301: 0.2811458110809326\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 303/500 [15:02<09:29,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 302: 0.1838466227054596\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 304/500 [15:05<09:14,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 303: 0.1990519016981125\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 305/500 [15:08<09:12,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 304: 0.33607834577560425\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 306/500 [15:10<08:37,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 305: 0.5429002046585083\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 307/500 [15:13<08:31,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 306: 0.38731974363327026\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 308/500 [15:16<08:53,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 307: 0.10994338989257812\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 309/500 [15:18<08:34,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 308: 0.37961167097091675\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 310/500 [15:21<08:38,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 309: 0.4912707507610321\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 311/500 [15:24<08:34,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 310: 0.1880035102367401\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 312/500 [15:27<08:41,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 311: 0.3165477514266968\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 313/500 [15:30<08:59,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 312: 0.07123802602291107\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 314/500 [15:33<09:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 313: 0.07858417928218842\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 315/500 [15:36<08:53,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 314: 0.20989617705345154\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 316/500 [15:39<09:04,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 315: 0.11969538778066635\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 317/500 [15:42<09:08,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 316: 0.0781765952706337\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 318/500 [15:45<08:57,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 317: 0.08962242305278778\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 319/500 [15:48<09:11,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 318: 0.1586659699678421\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 320/500 [15:51<09:13,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 319: 0.10476027429103851\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 321/500 [15:54<08:39,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 320: 0.09009715169668198\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 322/500 [15:56<08:18,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 321: 0.14794190227985382\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 323/500 [15:59<08:06,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 322: 0.29122620820999146\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 324/500 [16:01<07:47,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 323: 0.24281518161296844\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 325/500 [16:04<07:41,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 324: 0.25813180208206177\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 326/500 [16:07<07:40,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 325: 0.19122165441513062\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 327/500 [16:09<07:32,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 326: 0.2907734215259552\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 328/500 [16:12<07:34,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 327: 0.4957870543003082\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 329/500 [16:14<07:32,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 328: 0.20813632011413574\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 330/500 [16:17<07:28,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 329: 0.18304267525672913\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 331/500 [16:20<07:45,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 330: 0.17384947836399078\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 332/500 [16:23<07:23,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 331: 0.09212872385978699\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 333/500 [16:25<07:18,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 332: 0.27648231387138367\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 334/500 [16:28<07:06,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 333: 0.1923038363456726\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 335/500 [16:30<07:10,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 334: 0.538471519947052\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 336/500 [16:33<07:05,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 335: 0.5573964715003967\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 337/500 [16:35<07:04,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 336: 0.2638678550720215\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 338/500 [16:38<06:58,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 337: 0.4477464556694031\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 339/500 [16:40<06:53,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 338: 0.4658369719982147\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 340/500 [16:43<06:50,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 339: 0.31930404901504517\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 341/500 [16:46<06:54,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 340: 0.4138820171356201\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 342/500 [16:49<07:03,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 341: 0.2773594856262207\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 343/500 [16:53<08:08,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 342: 0.4866941273212433\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 344/500 [16:56<07:56,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 343: 0.5952972769737244\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 345/500 [16:59<08:08,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 344: 0.2706927955150604\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 346/500 [17:01<07:30,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 345: 0.5122681260108948\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 347/500 [17:04<07:21,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 346: 0.2086070328950882\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 348/500 [17:07<07:03,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 347: 0.2414797693490982\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 349/500 [17:09<06:53,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 348: 0.1871454268693924\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 350/500 [17:12<06:54,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 349: 0.2694108784198761\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 351/500 [17:15<06:47,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 350: 0.345874547958374\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 352/500 [17:17<06:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 351: 0.20187899470329285\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 353/500 [17:20<06:24,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 352: 0.31387433409690857\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 354/500 [17:23<06:26,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 353: 0.4082964360713959\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 355/500 [17:25<06:14,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 354: 0.16324955224990845\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 356/500 [17:29<07:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 355: 0.15804876387119293\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 357/500 [17:32<07:32,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 356: 0.1636783480644226\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 358/500 [17:37<08:08,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 357: 0.2299012541770935\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 359/500 [17:40<08:06,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 358: 0.3304268717765808\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 360/500 [17:44<08:07,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 359: 0.4139474034309387\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 361/500 [17:48<08:38,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 360: 0.543728768825531\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 362/500 [17:52<09:00,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 361: 0.41453856229782104\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 363/500 [17:56<08:39,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 362: 0.40557223558425903\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 364/500 [17:59<08:26,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 363: 0.22109347581863403\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 365/500 [18:03<08:22,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 364: 0.4256349205970764\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 366/500 [18:07<08:15,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 365: 0.3515664339065552\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 367/500 [18:10<08:04,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 366: 0.44746020436286926\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 368/500 [18:14<08:17,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 367: 0.5626869201660156\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 369/500 [18:18<08:05,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 368: 0.4552566111087799\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 370/500 [18:22<08:11,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 369: 0.42012104392051697\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 371/500 [18:26<08:26,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 370: 0.43726688623428345\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 372/500 [18:30<08:21,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 371: 0.38881757855415344\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 373/500 [18:34<08:26,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 372: 0.45130398869514465\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 374/500 [18:37<07:25,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 373: 0.34927377104759216\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 375/500 [18:39<06:48,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 374: 0.39299285411834717\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 376/500 [18:42<06:26,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 375: 0.2735835611820221\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 377/500 [18:45<06:05,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 376: 0.28883999586105347\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 378/500 [18:47<05:59,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 377: 0.2608034908771515\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 379/500 [18:50<05:57,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 378: 0.2950811982154846\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 380/500 [18:53<05:46,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 379: 0.3652920126914978\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 381/500 [18:56<05:32,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 380: 0.3044200837612152\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 382/500 [18:58<05:25,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 381: 0.33486807346343994\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 383/500 [19:01<05:15,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 382: 0.45290639996528625\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 384/500 [19:04<05:17,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 383: 0.42478591203689575\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 385/500 [19:07<05:18,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 384: 0.3600215017795563\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 386/500 [19:09<05:01,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 385: 0.2957487106323242\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 387/500 [19:12<04:55,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 386: 0.4099288880825043\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 388/500 [19:15<05:04,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 387: 0.4063661992549896\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 389/500 [19:17<04:49,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 388: 0.23233762383460999\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 390/500 [19:19<04:45,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 389: 0.37374234199523926\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 391/500 [19:22<04:44,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 390: 0.18673104047775269\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 392/500 [19:25<04:45,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 391: 0.4542233347892761\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 393/500 [19:27<04:44,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 392: 0.26030078530311584\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 394/500 [19:31<04:55,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 393: 0.6763589382171631\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 395/500 [19:33<04:42,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 394: 0.3005441725254059\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 396/500 [19:36<04:38,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 395: 0.5591220259666443\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 397/500 [19:38<04:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 396: 0.3064482510089874\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 398/500 [19:41<04:26,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 397: 0.3566354513168335\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 399/500 [19:44<04:25,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 398: 0.45201337337493896\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 400/500 [19:46<04:33,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 399: 0.492564857006073\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 401/500 [19:49<04:24,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 400: 0.5087897777557373\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 402/500 [19:52<04:30,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 401: 0.5770189762115479\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 403/500 [19:55<04:29,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 402: 0.14117541909217834\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 404/500 [19:57<04:19,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 403: 0.2588251531124115\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 405/500 [20:00<04:16,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 404: 0.48690667748451233\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 406/500 [20:03<04:19,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 405: 0.2991671562194824\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 407/500 [20:05<04:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 406: 0.4597117304801941\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 408/500 [20:08<04:08,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 407: 0.5429259538650513\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 409/500 [20:11<04:13,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 408: 0.6782620549201965\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 410/500 [20:14<04:01,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 409: 0.4798870086669922\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 411/500 [20:16<03:57,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 410: 0.18250030279159546\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 412/500 [20:19<03:57,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 411: 0.3567763864994049\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 413/500 [20:22<03:52,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 412: 0.452303946018219\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 414/500 [20:24<03:53,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 413: 0.5346634387969971\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 415/500 [20:27<03:51,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 414: 0.46504348516464233\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 416/500 [20:30<03:44,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 415: 0.32413679361343384\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 417/500 [20:32<03:43,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 416: 0.1576387882232666\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 418/500 [20:35<03:39,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 417: 0.4293571412563324\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 419/500 [20:38<03:32,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 418: 0.3950163424015045\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 420/500 [20:40<03:28,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 419: 0.43571820855140686\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 421/500 [20:43<03:27,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 420: 0.2092716544866562\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 422/500 [20:45<03:20,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 421: 0.3551068902015686\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 423/500 [20:48<03:21,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 422: 0.4853387475013733\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 424/500 [20:51<03:17,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 423: 0.3030133545398712\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 425/500 [20:53<03:17,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 424: 0.5611750483512878\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 426/500 [20:56<03:20,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 425: 0.6378599405288696\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 427/500 [20:58<03:08,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 426: 0.3329617381095886\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 428/500 [21:01<03:04,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 427: 0.36195695400238037\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 429/500 [21:04<03:05,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 428: 0.18084335327148438\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 430/500 [21:06<02:58,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 429: 0.48025280237197876\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 431/500 [21:09<02:59,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 430: 0.30846115946769714\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 432/500 [21:11<02:56,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 431: 0.1918516457080841\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 433/500 [21:14<02:52,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 432: 0.4041573107242584\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 434/500 [21:17<02:50,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 433: 0.3360513746738434\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 435/500 [21:19<02:49,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 434: 0.32489344477653503\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 436/500 [21:22<02:52,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 435: 0.3835742175579071\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 437/500 [21:25<03:02,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 436: 0.4322112798690796\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 438/500 [21:30<03:25,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 437: 0.1536291390657425\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 439/500 [21:33<03:27,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 438: 0.33394402265548706\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 440/500 [21:37<03:25,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 439: 0.1891193836927414\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 441/500 [21:40<03:23,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 440: 0.16900140047073364\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 442/500 [21:44<03:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 441: 0.2759181261062622\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 443/500 [21:47<03:10,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 442: 0.34484395384788513\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 444/500 [21:51<03:20,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 443: 0.548380434513092\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 445/500 [21:55<03:18,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 444: 0.3324929177761078\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 446/500 [21:58<03:15,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 445: 0.1603793054819107\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 447/500 [22:02<03:07,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 446: 0.1843995451927185\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 448/500 [22:05<03:02,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 447: 0.15734459459781647\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 449/500 [22:09<02:59,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 448: 0.11845068633556366\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 450/500 [22:12<02:53,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 449: 0.11598551273345947\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 451/500 [22:16<02:52,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 450: 0.33085528016090393\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 452/500 [22:18<02:38,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 451: 0.21775159239768982\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 453/500 [22:22<02:44,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 452: 0.13832588493824005\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 454/500 [22:27<02:50,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 453: 0.3720468580722809\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 455/500 [22:30<02:47,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 454: 0.45009395480155945\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 456/500 [22:33<02:25,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 455: 0.16391634941101074\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 457/500 [22:35<02:13,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 456: 0.3572631776332855\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 458/500 [22:38<02:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 457: 0.1798466444015503\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 459/500 [22:41<01:58,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 458: 0.4311576187610626\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 460/500 [22:44<01:54,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 459: 0.10997378826141357\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 461/500 [22:46<01:49,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 460: 0.2047349214553833\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 462/500 [22:49<01:45,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 461: 0.21440842747688293\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 463/500 [22:51<01:40,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 462: 0.14938423037528992\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 464/500 [22:54<01:37,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 463: 0.1853778064250946\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 465/500 [22:57<01:34,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 464: 0.18860450387001038\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 466/500 [22:59<01:30,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 465: 0.5474528670310974\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 467/500 [23:02<01:28,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 466: 0.3632793128490448\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 468/500 [23:05<01:24,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 467: 0.5689842700958252\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 469/500 [23:07<01:18,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 468: 0.31415095925331116\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 470/500 [23:10<01:21,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 469: 0.357582151889801\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 471/500 [23:13<01:17,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 470: 0.4616546332836151\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 472/500 [23:15<01:13,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 471: 0.2984784245491028\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 473/500 [23:18<01:10,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 472: 0.2570662200450897\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 474/500 [23:20<01:06,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 473: 0.40890902280807495\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 475/500 [23:23<01:07,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 474: 0.1684996634721756\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 476/500 [23:26<01:08,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 475: 0.4363882839679718\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 477/500 [23:29<01:03,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 476: 0.43679875135421753\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 478/500 [23:32<01:01,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 477: 0.41533589363098145\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 479/500 [23:35<00:58,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 478: 0.3282596170902252\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 480/500 [23:37<00:54,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 479: 0.33411160111427307\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 481/500 [23:40<00:51,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 480: 0.4327613413333893\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 482/500 [23:43<00:48,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 481: 0.2294328808784485\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 483/500 [23:45<00:44,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 482: 0.2649574279785156\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 484/500 [23:48<00:42,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 483: 0.3807980418205261\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 485/500 [23:50<00:39,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 484: 0.2204982489347458\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 486/500 [23:53<00:36,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 485: 0.11868283152580261\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 487/500 [23:55<00:33,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 486: 0.27920880913734436\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 488/500 [23:58<00:30,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 487: 0.1475156992673874\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 489/500 [24:00<00:27,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 488: 0.18858253955841064\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 490/500 [24:03<00:25,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 489: 0.4563702642917633\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 491/500 [24:06<00:23,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 490: 0.07800370454788208\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 492/500 [24:08<00:20,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 491: 0.3522760570049286\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 493/500 [24:11<00:18,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 492: 0.358690470457077\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 494/500 [24:14<00:15,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 493: 0.4794684648513794\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 495/500 [24:16<00:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 494: 0.4859917461872101\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 496/500 [24:19<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 495: 0.2029644250869751\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 497/500 [24:21<00:07,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 496: 0.2557211220264435\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 498/500 [24:24<00:05,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 497: 0.27890947461128235\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 499/500 [24:27<00:02,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 498: 0.5206931233406067\n",
      "(1024, 2048, 3) torch.Size([1024, 2048, 3])\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [24:29<00:00,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU for frame 499: 0.20366807281970978\n",
      "Mean IoU: 0.3518190384954214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######VALIDATION or saving the pseudo labels########\n",
    "val_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",split='val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# print(len(val_dataset))\n",
    "#set seed\n",
    "torch.manual_seed(0)\n",
    "sampling = 10 # more than 15 make it less accurate!!!\n",
    "threshold = 0.45\n",
    "\n",
    "val_flag= True\n",
    "if val_flag:\n",
    "    processor = AutoProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "    model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "    ##ckpt = \"/home/avalocal/thesis23/KD/sam2/checkpoints/clipseg_finetuned_semantic_cityscapes_1e-4.pth\"\n",
    "    ckpt=\"/home/avalocal/thesis23/KD/sam2/checkpoints/clipseg_finetuned_semantic_cityscapes_1e-5.pth\"\n",
    "    dict = torch.load(ckpt)\n",
    "    model.load_state_dict(dict)\n",
    "    save_dir = \"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes/gCLIP/train_extra\"\n",
    "    model.eval()\n",
    "\n",
    "    MIOU= 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(val_loader)):\n",
    "\n",
    "            frame = i\n",
    "            image,gt_rgb_mask, _= batch ##1, 3, H, W | 1,11, H, W\n",
    "\n",
    "            # image, filename = batch\n",
    "            # filename = filename[0]\n",
    "            \n",
    "            stuff_mask = torch.zeros(len(dic), 1024, 2048)\n",
    "            assigned_pixels = torch.zeros(1024, 2048, dtype=torch.bool)\n",
    "            points =torch.zeros(len(dic), sampling, 2)\n",
    "            image *=255.0\n",
    "            image=image[0].permute(1, 2, 0).numpy().copy()#.astype(np.uint8) #H, W, 3\n",
    "            image = image.astype(np.uint8)\n",
    "            # gt_rgb_mask = gt_rgb_mask[0].cpu().numpy()#.transpose(1, 2, 0)        \n",
    "\n",
    "            for j in range(len(dic)):            \n",
    "                prompt = f\"{dic[j]}\"\n",
    "                inputs = processor(text=prompt, images=image, padding=True, return_tensors=\"pt\")\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.logits\n",
    "                logits = logits.unsqueeze(0)\n",
    "                logits = torch.nn.functional.interpolate(logits, size=(1024, 2048), mode=\"bilinear\", align_corners=False)\n",
    "                logits = logits.squeeze(0)\n",
    "                logits = logits.sigmoid()\n",
    "                mask = logits > threshold\n",
    "                mask = mask & ~assigned_pixels\n",
    "\n",
    "                stuff_mask[j] = mask\n",
    "                assigned_pixels = assigned_pixels | mask\n",
    "                \n",
    "            for k in range(len(dic)):\n",
    "\n",
    "                idx_points = torch.nonzero(stuff_mask[k], as_tuple=False)\n",
    "                if idx_points.size(0) >= sampling:\n",
    "                    selected_indices = random.sample(range(idx_points.size(0)), sampling)\n",
    "                    selected_points = idx_points[selected_indices]\n",
    "                else:\n",
    "                    selected_points = torch.zeros(sampling, 2, dtype=torch.int64)\n",
    "                    selected_points[:idx_points.size(0)] = idx_points\n",
    "                points[k] = selected_points\n",
    "            color_mask = colorize_mask(stuff_mask) #1024, 2048, 3\n",
    "            color_mask = color_mask.astype(np.uint8)\n",
    "\n",
    "            predictor.set_image(image)\n",
    "            genral_mask = torch.zeros(len(dic), 1024, 2048)\n",
    "            \n",
    "            for z in range(len(dic)):            \n",
    "                prompt = f\"{dic[z]}\"\n",
    "                points_ = points[z]\n",
    "                points_ = points_[:, [1, 0]]\n",
    "                \n",
    "                tmp, scores, _ = predictor.predict(\n",
    "                    point_coords=points_,\n",
    "                    point_labels=[1]*len(points_),\n",
    "                    multimask_output=False,\n",
    "                )\n",
    "                tmp = tmp.squeeze(0)\n",
    "                tmp = torch.from_numpy(tmp).to(device)\n",
    "                genral_mask[z] = tmp\n",
    "                \n",
    "            pseudo_mask = colorize_mask(genral_mask)\n",
    "            pseudo_mask = pseudo_mask.astype(np.uint8)\n",
    "            \n",
    "            save =False\n",
    "            if save:\n",
    "                #save in the directory/cityscapes/gCLIP/train_extra/city/imagename.png\n",
    "                city=filename.split(\"_\")[0]\n",
    "                save_path = os.path.join(save_dir, city)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                # heilbronn_000000_000531_leftImg8bit.png -> # heilbronn_000000_000531_gclip_color.png\n",
    "                filename = filename.replace(\"leftImg8bit\", \"gclip_color\")\n",
    "                save_path = os.path.join(save_path, filename)\n",
    "                Image.fromarray(pseudo_mask).save(save_path)\n",
    "                output = np.zeros_like(color_mask)\n",
    "                for i in range(len(dic)):\n",
    "                    color = num_to_color[i]\n",
    "                    class_mask = np.all(gt_rgb_mask == color, axis=-1)\n",
    "                    output[class_mask] = color\n",
    "            \n",
    "                \n",
    "            #show psudo mask and gt rgb mask\n",
    "            #gt_rgb_mask -> [1, 1024, 2048, 3]\n",
    "            # gt_rgb_mask = gt_rgb_mask[0].cpu().numpy()\n",
    "            gt_rgb_mask = gt_rgb_mask[0]\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            print(pseudo_mask.shape, gt_rgb_mask.shape)\n",
    "            # fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            # ax[0].imshow(pseudo_mask)\n",
    "            # ax[0].set_title(\"Pseudo mask\") #H, W, 3\n",
    "            # ax[1].imshow(gt_rgb_mask)\n",
    "            # ax[1].set_title(\"GT mask\") #H, W, 3\n",
    "            # plt.show()\n",
    "            print(type(pseudo_mask), type(gt_rgb_mask)) #numpy, tensor\n",
    "            pseudo_mask = torch.from_numpy(pseudo_mask)\n",
    "\n",
    "\n",
    "            miou_ = compute_miou(pseudo_mask, gt_rgb_mask)\n",
    "            print(f\"MIoU for frame {frame}: {miou_}\")\n",
    "            MIOU += miou_\n",
    "\n",
    "        print(f\"Mean IoU: {MIOU / 500}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (5.2.0)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.22). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "#Dataloader for the pseudo labels\n",
    "import os, sys\n",
    "import numpy as np\n",
    "KD_path = \"/home/avalocal/thesis23/KD\"\n",
    "sys.path.append(KD_path)\n",
    "import os, sys, glob, cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from labels import labels\n",
    "# import transforms\n",
    "import albumentations as A\n",
    "\n",
    "dic = {0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence', 5: 'pole', 6: 'traffic light', 7: 'traffic sign', 8: 'vegetation', 9: 'terrain', 10: 'sky'}\n",
    "num_to_color = { 0: [128, 64, 128], 1: [244, 35, 232], 2: [70, 70, 70],\n",
    "    3: [102, 102, 156], 4: [190, 153, 153], 5: [153, 153, 153],\n",
    "    6: [250, 170, 30], 7: [220, 220, 0], 8: [107, 142, 35], 9: [152, 251, 152],\n",
    "    10: [70, 130, 180]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "id2trainId = { label.id: label.trainId for label in labels }\n",
    "trainId2color = { label.trainId: label.color for label in labels }\n",
    "\n",
    "\n",
    "#dataset getting images and labels\n",
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, root_dir, split='train_extra'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.H = 798\n",
    "        self.W = 798\n",
    "        self.train_transforms = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # A.RandomBrightnessContrast(p=0.5),\n",
    "            # A.ColorJitter(contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
    "            # A.GaussianBlur(p=0.2),\n",
    "            A.RandomResizedCrop(self.H, self.W)\n",
    "        ])\n",
    "       \n",
    "        if self.split in ['train_extra']:\n",
    "\n",
    "            self.pseudo_dir = os.path.join(self.root_dir, 'gCLIP', self.split)\n",
    "\n",
    "            self.pseudo_files = glob.glob(os.path.join(self.pseudo_dir, '*/*'))\n",
    "            self.image_files = [file.replace(\"gclip_color\", \"leftImg8bit\") for file in self.pseudo_files]\n",
    "            self.image_files = [file.replace(\"gCLIP\", \"leftImg8bit\") for file in self.image_files]\n",
    "\n",
    "            self.image_files.sort()\n",
    "            self.pseudo_files.sort()\n",
    "\n",
    "        elif self.split in ['val', 'train', 'test']:\n",
    "\n",
    "            self.image_dir = os.path.join(self.root_dir, 'leftImg8bit', self.split)\n",
    "            self.label_dir = os.path.join(self.root_dir, 'gtFine', self.split)\n",
    "\n",
    "            self.image_files = glob.glob(os.path.join(self.image_dir, '*/*'))\n",
    "            self.label_files = glob.glob(os.path.join(self.label_dir, '*/*_labelIds.png'))\n",
    "            self.color_files = glob.glob(os.path.join(self.label_dir, '*/*_color.png'))\n",
    "\n",
    "            self.image_files.sort()\n",
    "            self.label_files.sort()\n",
    "            self.color_files.sort()\n",
    "\n",
    "        self.stuff_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        self.instace_classes = [11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert os.path.exists(self.image_files[idx]), self.image_files[idx]\n",
    "        file_name = os.path.basename(self.image_files[idx])\n",
    "        image = cv2.imread(self.image_files[idx], cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #H, W, C\n",
    "        cropped_image = image[0:970, 0:2048]\n",
    "        image = cv2.resize(cropped_image, (2048, 1024), interpolation=cv2.INTER_LINEAR)\n",
    "        # image = image / 255.0\n",
    "        image =np.array(image)\n",
    "\n",
    "        if self.split in ['train_extra']:\n",
    "\n",
    "            label_rgb = cv2.imread(self.pseudo_files[idx], cv2.IMREAD_COLOR)\n",
    "            label_rgb = cv2.cvtColor(label_rgb, cv2.COLOR_BGR2RGB) #H, W, C\n",
    "            label = torch.ones(1024, 2048) * 11\n",
    "            for i in range(11):\n",
    "                color = num_to_color[i]\n",
    "                mask = (label_rgb == color).all(axis=-1)\n",
    "                label[mask] = i\n",
    "            # label = label.permute(2, 0, 1).float()\n",
    "            label.squeeze(0)\n",
    "\n",
    "            # print(label.shape, image.shape)\n",
    "\n",
    "            #label to numpy\n",
    "            label = label.numpy()\n",
    "            transformed = self.train_transforms(image=image, mask=label)\n",
    "            image = transformed['image']\n",
    "            label = transformed['mask']\n",
    "\n",
    "        elif self.split in ['train']:\n",
    "            label = cv2.imread(self.label_files[idx], cv2.IMREAD_GRAYSCALE) #H, W\n",
    "            label = np.vectorize(id2trainId.get)(label)\n",
    "            for i in self.instace_classes:\n",
    "                label[label == i] = 11\n",
    "\n",
    "            # print(label.shape, image.shape)\n",
    "\n",
    "            transformed = self.train_transforms(image=image, mask=label)\n",
    "            image = transformed['image']\n",
    "            label = transformed['mask']\n",
    "        elif self.split in ['val']:\n",
    "            label = cv2.imread(self.label_files[idx], cv2.IMREAD_GRAYSCALE) #H, W\n",
    "            label = np.vectorize(id2trainId.get)(label)\n",
    "            for i in self.instace_classes:\n",
    "                label[label == i] = 11\n",
    "\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float() #3, H, W\n",
    "        label = torch.from_numpy(label).float() #1, H, W\n",
    "        return image, label  # 3, H, W | 1, H, W\n",
    "\n",
    "\n",
    "\n",
    "def compute_miou(pred, gt):\n",
    "    '''\n",
    "    pred : 1, H, W\n",
    "    gt : 1, H, W\n",
    "    '''\n",
    "    num_classes = len(dic)\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = np.all(pred == cls, axis=0)\n",
    "        gt_mask = np.all(gt == cls, axis=0)\n",
    "        intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "        union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "        if union <=1e-9:\n",
    "            ious.append(np.nan)\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    miou = np.nanmean(ious)\n",
    "    return miou\n",
    "\n",
    "# # #exaple of dataset\n",
    "val_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",split='train_extra')\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "# batch = next(iter(val_loader))\n",
    "# image, label = batch\n",
    "# print(image.shape, label.shape) #1, 3, 2048, 1024]) torch.Size([1, 1024, 2048]\n",
    "\n",
    "# #show image and label\n",
    "# ax, fig = plt.subplots(1, 2)\n",
    "# image = image\n",
    "# print(type(image[0]), type(label[0])) #<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
    "# print(image[0].dtype, label[0].dtype) #torch.float32 torch.float32\n",
    "# print(image[0].max(), image[0].min())\n",
    "# fig[0].imshow(image[0].permute(1, 2, 0).numpy().astype(np.uint8))\n",
    "# fig[1].imshow(label[0].numpy())\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train atudent models on the pseudo labels\n",
    "from transformers import AutoProcessor, CLIPSegForImageSegmentation\n",
    "# from model import SemanticStudent   \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "# At the start of your script, after imports\n",
    "from torch.amp import autocast, GradScaler\n",
    "import wandb\n",
    "\n",
    "\n",
    "KD= False\n",
    "if KD:\n",
    "\n",
    "    # Initialize the scaler\n",
    "    scaler = GradScaler()\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "    torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "    torch.backends.cuda.enable_math_sdp(False)\n",
    "\n",
    "    # torch.cuda.empty_cache()\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    train_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",\n",
    "                split='train_extra')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "    val_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",split='val')\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    student_model = SemanticStudent()\n",
    "\n",
    "    amp_dtype = torch.bfloat16  # Instead of default float16\n",
    "\n",
    "    #to multi-gpu\n",
    "    student_model.to(device)\n",
    "    student_model = nn.DataParallel(student_model)\n",
    "    student_model.train()\n",
    "\n",
    "    epochs = 50\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5, weight_decay=1e-2, betas=(0.9, 0.999))\n",
    "    optimizer = torch.optim.AdamW([\n",
    "    {'params': [p for n, p in student_model.named_parameters() if \"image_encoder\" in n], 'lr': 6e-5}, \n",
    "    {'params': [p for n, p in student_model.named_parameters() if not \"image_encoder\" in n], 'lr': 3e-4}, \n",
    "    ], weight_decay=0.1, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=1e-8)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    #generate glob name time/date\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    date_time = now.strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    name_experiment = f\"semantic_student_cityscapes_{date_time}\"\n",
    "    #wandb\n",
    "    wandb.init(project=\"semantic_seg\",\n",
    "                config={\n",
    "                    \"model\": \"semantic_student\",\n",
    "                    \"dataset\": \"cityscapes\",\n",
    "                    \"epochs\": epochs,\n",
    "                    \"batch_size\": 8,\n",
    "                    \"learning_rate\": 1e-5,\n",
    "                    \"weight_decay\": 1e-2,\n",
    "                    \"betas\": (0.9, 0.999),\n",
    "                    \"scheduler\": \"CosineAnnealingLR\",\n",
    "                    \"scheduler_T_max\": len(train_loader)*epochs,\n",
    "                    \"scheduler_eta_min\": 1e-8\n",
    "                },\n",
    "                name=name_experiment\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    #student model training\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        student_model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "\n",
    "            # if i==10: break\n",
    "            \n",
    "            image, pseudo_mask= batch\n",
    "            image = image.to(device)\n",
    "\n",
    "            pseudo_mask = pseudo_mask.to(device)\n",
    "            pseudo_mask = pseudo_mask.squeeze(1)\n",
    "            pseudo_mask = pseudo_mask.long()\n",
    "\n",
    "            # print(image.shape, pseudo_mask.shape) #16, 3, 1024, 2048 | 16, 1024, 2048\n",
    "\n",
    "            # Mixed precision training\n",
    "            with autocast():\n",
    "                outputs = student_model(image)\n",
    "                logits = outputs[\"pred_masks\"]\n",
    "                # print(logits.shape) #16, 12, 256, 256\n",
    "                # print(pseudo_mask.shape) #16, 1024, 1024\n",
    "                # print(pseudo_mask.unique())\n",
    "                \n",
    "                logits = torch.nn.functional.interpolate(logits, size=(1024, 1024), mode=\"bilinear\", align_corners=False)\n",
    "                # print(logits.shape, pseudo_mask.shape) #16, 12, 256, 256 | 16, 1024, 1024\n",
    "\n",
    "                loss = criterion(logits, pseudo_mask)\n",
    "\n",
    "            # Optimize with gradient scaling\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # scheduler.step()\n",
    "            # running_loss += loss.item()\n",
    "\n",
    "        wandb.log({\"train_loss\": running_loss / len(train_loader)})\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        #validation for evry 10 epochs or the first epoch\n",
    "        # if epoch % 10 == 0 or epoch == 0:\n",
    "\n",
    "\n",
    "        student_model.eval()\n",
    "        MIOU= 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(tqdm(val_loader)):\n",
    "                torch.cuda.empty_cache()\n",
    "                image, label = batch\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                label = label.squeeze(1)\n",
    "                label = label.long()\n",
    "\n",
    "\n",
    "\n",
    "                with autocast():\n",
    "                    #resize image to 1024, 1024\n",
    "                    image = torch.nn.functional.interpolate(image, size=(1024, 1024), mode=\"bilinear\", align_corners=False)\n",
    "                    outputs = student_model(image)\n",
    "                    logits = outputs[\"pred_masks\"]\n",
    "                    logits = torch.nn.functional.interpolate(\n",
    "                        logits, \n",
    "                        size=(1024, 2048), \n",
    "                        mode=\"bilinear\", \n",
    "                        align_corners=False\n",
    "                    )\n",
    "                    logits = logits.argmax(1)\n",
    "\n",
    "                #logits : 1, 1024, 1024\n",
    "                #label : 1, 1024, 1024\n",
    "                # print(logits.shape, label.shape)\n",
    "                # logits = logits.long()\n",
    "                miou = compute_miou(logits.cpu().numpy(), label.cpu().numpy())\n",
    "                MIOU += miou\n",
    "\n",
    "        wandb.log({\"mIoU\": MIOU / len(val_loader)})    \n",
    "        print(f\"---> Mean IoU for epoch {epoch}: {MIOU / len(val_loader)}\")\n",
    "\n",
    "    #save the model\n",
    "    # torch.save(student_model.state_dict(), \"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_KD_cityscapes.pth\")\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': student_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'epoch': epoch\n",
    "        }, \"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_KD_70epochs_cityscapes.pth\") #it was 50 epochs not 70@@\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "#best res we can get here is maximum of teacher model = 36.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/avalocal/thesis23/KD/sam2/training/finetunings', '', '/opt/ros/foxy/lib/python3.8/site-packages', '/home/avalocal/miniconda3/envs/KD/lib/python310.zip', '/home/avalocal/miniconda3/envs/KD/lib/python3.10', '/home/avalocal/miniconda3/envs/KD/lib/python3.10/lib-dynload', '/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages', '/home/avalocal/thesis23/KD/Grounded-SAM-2/grounding_dino', '/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg', '/home/avalocal/thesis23/KD/detectron2', '/home/avalocal/thesis23/KD/utils/mmdetection', '/home/avalocal/thesis23/KD', '/tmp/tmpdnq2hom3', '/home/avalocal/thesis23/KD/DPT', '/home/avalocal/thesis23/KD', '/home/avalocal/thesis23/KD/UniMatch-V2']\n"
     ]
    }
   ],
   "source": [
    "#fine tuning SAM2 with Cityscapes dataset\n",
    "\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "dpt_path = \"/home/avalocal/thesis23/KD/DPT\"\n",
    "sys.path.append(dpt_path)\n",
    "KD_path = \"/home/avalocal/thesis23/KD\"\n",
    "sys.path.append(KD_path)\n",
    "uni_path = \"/home/avalocal/thesis23/KD/UniMatch-V2\"\n",
    "sys.path.append(uni_path)\n",
    "#show sys path\n",
    "print(sys.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in Million 97.527628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaghavi-pardis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/avalocal/thesis23/KD/sam2/training/finetunings/wandb/run-20241218_214525-4sw34r90</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/taghavi-pardis/semantic_seg/runs/4sw34r90' target=\"_blank\">semantic_student_cityscapes_expert_12_18_2024_21_45_max_decay_steps25</a></strong> to <a href='https://wandb.ai/taghavi-pardis/semantic_seg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/taghavi-pardis/semantic_seg' target=\"_blank\">https://wandb.ai/taghavi-pardis/semantic_seg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/taghavi-pardis/semantic_seg/runs/4sw34r90' target=\"_blank\">https://wandb.ai/taghavi-pardis/semantic_seg/runs/4sw34r90</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:36<00:00, 13.60it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 13.91it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.08it/s]\n",
      "100%|| 372/372 [02:14<00:00,  2.76it/s]\n",
      "100%|| 500/500 [00:34<00:00, 14.58it/s]\n",
      "100%|| 372/372 [02:12<00:00,  2.81it/s]\n",
      "100%|| 500/500 [00:33<00:00, 14.72it/s]\n",
      "100%|| 372/372 [02:12<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:33<00:00, 14.76it/s]\n",
      "100%|| 372/372 [02:11<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:34<00:00, 14.63it/s]\n",
      "100%|| 372/372 [02:11<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:34<00:00, 14.61it/s]\n",
      "100%|| 372/372 [02:12<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.21it/s]\n",
      "100%|| 372/372 [02:12<00:00,  2.81it/s]\n",
      "100%|| 500/500 [00:33<00:00, 14.86it/s]\n",
      "100%|| 372/372 [02:12<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.26it/s]\n",
      "100%|| 372/372 [02:11<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:33<00:00, 14.74it/s]\n",
      "100%|| 372/372 [02:12<00:00,  2.82it/s]\n",
      "100%|| 500/500 [00:34<00:00, 14.62it/s]\n",
      "100%|| 372/372 [02:13<00:00,  2.79it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.10it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.10it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.17it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 13.96it/s]\n",
      "100%|| 372/372 [02:16<00:00,  2.73it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.00it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.22it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 13.95it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 14.12it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 13.91it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:36<00:00, 13.84it/s]\n",
      "100%|| 372/372 [02:15<00:00,  2.74it/s]\n",
      "100%|| 500/500 [00:35<00:00, 13.92it/s]\n",
      "  3%|         | 13/372 [00:07<03:24,  1.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 164\u001b[0m\n\u001b[1;32m    154\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scaler.scale(loss).backward()\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scaler.unscale_(optimizer)\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# # torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=0.1)\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scaler.step(optimizer)\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# scaler.update()\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# running_loss += loss.item()\u001b[39;00m\n\u001b[1;32m    172\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train atudent models on the real label!!!!!\n",
    "\n",
    "# from model import SemanticStudent   \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.amp import autocast, GradScaler\n",
    "import wandb\n",
    "from modelUni.semseg.dpt import DPT\n",
    "\n",
    "# from model.semseg.dpt import DPT\n",
    "expert = True \n",
    "if expert:\n",
    "\n",
    "    # Initialize the scaler\n",
    "    scaler = GradScaler()\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "    torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "    torch.backends.cuda.enable_math_sdp(False)\n",
    "\n",
    "    # torch.cuda.empty_cache()\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    train_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",\n",
    "                split='train')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "    val_dataset = Cityscapes(root_dir=\"/media/avalocal/T7/pardis/pardis/perception_system/datasets/cityscapes\",split='val')\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # student_model = SemanticStudent()\n",
    "    # # ckpt = \"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_KD_cityscapes.pth\"\n",
    "    # # ckpt = \"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_KD_70epochs_cityscapes.pth\"\n",
    "    # # dict = torch.load(ckpt)\n",
    "    # # new_state_dict = {}\n",
    "    # # for k, v in dict['model_state_dict'].items():\n",
    "    # #     # print(k)\n",
    "    # #     if \"module\" in k:\n",
    "    # #         k = k.replace(\"module.\", \"\")\n",
    "    # #     new_state_dict[k] = v\n",
    "    # # student_model.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "    \n",
    "    #'base': {'encoder_size': 'base', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    student_model = DPT(\n",
    "        encoder_size='base',\n",
    "        features=128,\n",
    "        out_channels=[96, 192, 384, 768],\n",
    "        use_bn=False,\n",
    "        nclass=12\n",
    "    )\n",
    "\n",
    "    pretrained =\"/home/avalocal/thesis23/KD/UniMatch-V2/dinov2_vitb14_pretrain.pth\"\n",
    "    state_dict = torch.load(pretrained)\n",
    "    student_model.backbone.load_state_dict(state_dict, strict = True)\n",
    "\n",
    "    #print number of parameters in M\n",
    "    params = sum(p.numel() for p in student_model.parameters())\n",
    "    print(f\"Number of parameters in Million {params/1e6}\")\n",
    "\n",
    "    H, W = 798, 798\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    amp_dtype = torch.bfloat16  # Instead of default float16\n",
    "    student_model.to(device)\n",
    "    student_model = nn.DataParallel(student_model)\n",
    "    student_model.train()\n",
    "\n",
    "    epochs = 180 #UNIMATCHV2 paper\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-5, weight_decay=1e-2, betas=(0.9, 0.999))\n",
    "\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': [p for n, p in student_model.named_parameters() if \"image_encoder\" in n], 'lr': 5e-6}, \n",
    "        {'params': [p for n, p in student_model.named_parameters() if not \"image_encoder\" in n], 'lr': 2e-4},  #40x\n",
    "        ], weight_decay=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=1e-8)\n",
    "    scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=len(train_loader)*epochs,  power=0.9)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    #generate glob name time/date\n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    date_time = now.strftime(\"%m_%d_%Y_%H_%M_max_decay_steps%S\")\n",
    "    name_experiment = f\"semantic_student_cityscapes_expert_{date_time}\"\n",
    "    #wandb\n",
    "    wandb.init(project=\"semantic_seg\",\n",
    "                config={\n",
    "                    \"model\": \"semantic_student\",\n",
    "                    \"dataset\": \"cityscapes\",\n",
    "                    \"epochs\": epochs,\n",
    "                    \"batch_size\": 8,\n",
    "                    \"learning_rate\": 1e-5,\n",
    "                    \"weight_decay\": 1e-2,\n",
    "                    \"betas\": (0.9, 0.999),\n",
    "                    \"scheduler\": \"CosineAnnealingLR\",\n",
    "                    \"scheduler_T_max\": len(train_loader)*epochs,\n",
    "                    \"scheduler_eta_min\": 1e-8\n",
    "                },\n",
    "                name=name_experiment\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    #student model training\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        student_model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(tqdm(train_loader)):\n",
    "\n",
    "            # if i==10: break\n",
    "            \n",
    "            image, maskGT = batch\n",
    "            image = image.to(device)\n",
    "            image/=255.0\n",
    "\n",
    "            maskGT = maskGT.to(device)\n",
    "            maskGT = maskGT.squeeze(1)\n",
    "            maskGT = maskGT.long()\n",
    "\n",
    "            # print(image.shape, pseudo_mask.shape) #16, 3, 1024, 2048 | 16, 1024, 2048\n",
    "\n",
    "            # Mixed precision training\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = student_model(image)\n",
    "                # logits = outputs[\"pred_masks\"] #B, 12, 256, 256\n",
    "                logits =outputs\n",
    "                logits = torch.nn.functional.interpolate(logits, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "                # print(logits.shape, pseudo_mask.shape) #16, 12, 256, 256 | 16, 1024, 1024\n",
    "                #maskGT : B, 1024, 1024\n",
    "                cross = criterion(logits, maskGT)\n",
    "                # dice_loss = 1 - (2 * (logits * maskGT).sum() + 1) / (logits.sum() + maskGT.sum() + 1)\n",
    "                loss = cross #+ dice_loss * 0.1\n",
    "\n",
    "\n",
    "            # Optimize with gradient scaling\n",
    "            optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # scheduler.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            # torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=0.1)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # scheduler.step()\n",
    "            # running_loss += loss.item()\n",
    "\n",
    "        wandb.log({\"train_loss\": running_loss / len(train_loader)})\n",
    "        # print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        #validation for evry 10 epochs or the first epoch\n",
    "        # if epoch % 10 == 0 or epoch == 0:\n",
    "\n",
    "\n",
    "        student_model.eval()\n",
    "        MIOU= 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(tqdm(val_loader)):\n",
    "                torch.cuda.empty_cache()\n",
    "                image, label = batch\n",
    "                image/=255.0\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                label = label.squeeze(1)\n",
    "                label = label.long()\n",
    "\n",
    "                # with autocast(device_type='cuda'):\n",
    "                #resize img to 1024, 1024\n",
    "                # image = torch.nn.functional.interpolate(image, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "                #instead of resizing the image just crop it \n",
    "                crop1 = image[:, :, 0:1024, 0:1024]\n",
    "                crop2 = image[:, :, 0:1024, 1024:2048]\n",
    "                with autocast(device_type='cuda'):\n",
    "\n",
    "                    outputs1 = student_model(crop1)\n",
    "                    outputs2 = student_model(crop2)\n",
    "\n",
    "                logits1 = outputs1[\"pred_masks\"] \n",
    "                logits2 = outputs2[\"pred_masks\"]\n",
    "\n",
    "                logits1 = torch.nn.functional.interpolate(logits1, size=(1024, 1024), mode=\"bilinear\", align_corners=False)\n",
    "                logits2 = torch.nn.functional.interpolate(logits2, size=(1024, 1024), mode=\"bilinear\", align_corners=False)\n",
    "                \n",
    "                #B, 12, 1024, 1024 + B, 12, 1024, 1024 -> B, 12, 2048, 1024\n",
    "                logits = torch.cat([logits1, logits2], dim=3) #B, 12, 2048, 1024\n",
    "                logits = logits.argmax(1)\n",
    "                miou = compute_miou(logits.cpu().numpy(), label.cpu().numpy())\n",
    "                MIOU += miou\n",
    "\n",
    "\n",
    "                # outputs = student_model(image)\n",
    "                # # logits = outputs[\"pred_masks\"]\n",
    "                # logits = outputs\n",
    "                # logits = torch.nn.functional.interpolate(\n",
    "                #     logits, \n",
    "                #     size = (1024, 2048),\n",
    "                #     mode=\"bilinear\", \n",
    "                #     align_corners=False\n",
    "                # )\n",
    "                # logits = logits.argmax(1)\n",
    "                # miou = compute_miou(logits.cpu().numpy(), label.cpu().numpy())\n",
    "                # MIOU += miou\n",
    "\n",
    "        #checkpoint every 10 epochs\n",
    "        save=False\n",
    "        if save and epoch % 10 == 0:\n",
    "            torch.save({\n",
    "                'model_state_dict': student_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'epoch': epoch\n",
    "                }, f\"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_expert_cityscapes_{epoch}.pth\")\n",
    "\n",
    "        wandb.log({\"mIoU\": MIOU / len(val_loader)})    \n",
    "        wandb.log({\"epoch\": epoch})\n",
    "        wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    #save the model\n",
    "    # torch.save(student_model.state_dict(), \"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_KD_cityscapes.pth\")\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': student_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'epoch': epoch\n",
    "        }, \"/home/avalocal/thesis23/KD/sam2/checkpoints/semantic_student_finetuned_expert_no_pretrained_cityscapes.pth\")\n",
    "\n",
    "    wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized weights for non-VisionTransformer parts of the model.\n",
      "number of parameters in Million:  124.005438\n",
      "torch.Size([4, 11, 480, 480])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avalocal/miniconda3/envs/KD/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (5.2.0)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "Some weights of DPTForSemanticSegmentation were not initialized from the model checkpoint at Intel/dpt-large-ade and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.batch_norm1.bias', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm1.num_batches_tracked', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm1.running_mean', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm1.running_var', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm1.weight', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm2.bias', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm2.num_batches_tracked', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm2.running_mean', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm2.running_var', 'neck.fusion_stage.layers.0.residual_layer1.batch_norm2.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
